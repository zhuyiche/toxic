{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy as sp\n",
    "from scipy.sparse import hstack, vstack\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_variable_pickle(var, name, model = False):\n",
    "    filename = name + '.pickle'\n",
    "    if model:\n",
    "        joblib.dump(var, filename = filename)\n",
    "    else:  \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(var, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_variable_pickle(name, model = False):\n",
    "    filename = name\n",
    "    if model:\n",
    "        return joblib.load(filename = filename)\n",
    "    else:\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_system(os):\n",
    "    if os == 'mac':\n",
    "        train_path = '/Users/yichen/Desktop/toxic/input/train.csv'\n",
    "        test_path = '/Users/yichen/Desktop/toxic/input/test.csv'\n",
    "    elif os == 'linux':\n",
    "        train_path = '/home/yichen/Desktop/toxic/input/train.csv'\n",
    "        test_path = '/home/yichen/Desktop/toxic/input/test.csv'\n",
    "    elif os == 'aws':\n",
    "        train_path = 'train.csv'\n",
    "        test_path = 'test.csv'\n",
    "    \n",
    "    train = pd.read_csv(train_path).fillna(' ')\n",
    "    test = pd.read_csv(test_path).fillna(' ')\n",
    "    return train, test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(true, estimate):\n",
    "    acc = accuracy_score(true, estimate)\n",
    "    logloss = log_loss(true, estimate)\n",
    "    auc = roc_auc_score(true, esimate)\n",
    "    print(\"accuracy score: {}, logloss: {}, auc: {}\".format(acc, logloss, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-576ba34bb56a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = choose_system('linux')\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = {\n",
    "    \"&lt;3\": \" good \", \":d\": \" good \",\n",
    "    \":dd\": \" good \",\n",
    "    \":p\": \" good \",\n",
    "    \"8)\": \" good \",\n",
    "    \":-)\": \" good \",\n",
    "    \":)\": \" good \",\n",
    "    \";)\": \" good \",\n",
    "    \"(-:\": \" good \",\n",
    "    \"(:\": \" good \",\n",
    "    \"yay!\": \" good \",\n",
    "    \"yay\": \" good \",\n",
    "    \"yaay\": \" good \",\n",
    "    \"yaaay\": \" good \",\n",
    "    \"yaaaay\": \" good \",\n",
    "    \"yaaaaay\": \" good \",\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" bad \",\n",
    "    \":(\": \" bad \",\n",
    "    \":s\": \" bad \",\n",
    "    \":-s\": \" bad \",\n",
    "    \"&lt;3\": \" heart \",\n",
    "    \":d\": \" smile \",\n",
    "    \":p\": \" smile \",\n",
    "    \":dd\": \" smile \",\n",
    "    \"8)\": \" smile \",\n",
    "    \":-)\": \" smile \",\n",
    "    \":)\": \" smile \",\n",
    "    \";)\": \" smile \",\n",
    "    \"(-:\": \" smile \",\n",
    "    \"(:\": \" smile \",\n",
    "    \":/\": \" worry \",\n",
    "    \":&gt;\": \" angry \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" sad \",\n",
    "    \":(\": \" sad \",\n",
    "    \":s\": \" sad \",\n",
    "    \":-s\": \" sad \",\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\",\n",
    "    r\"\\bdon't\\b\": \"do not\",\n",
    "    r\"\\bdoesn't\\b\": \"does not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bcan't\\b\": \"can not\",\n",
    "    r\"\\bcannot\\b\": \"can not\",\n",
    "    r\"\\bi'm\\b\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"r\": \"are\",\n",
    "    \"u\": \"you\",\n",
    "    \"haha\": \"ha\",\n",
    "    \"hahaha\": \"ha\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"cannot\": \"can not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"i'll\" : \"i will\",\n",
    "    \"its\" : \"it is\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"'s\" : \" is\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"weren't\" : \"were not\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [i for i in repl.keys()]\n",
    "\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "ltr = train[\"comment_text\"].tolist()\n",
    "keys = [i for i in repl.keys()]\n",
    "\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "ltr = train[\"comment_text\"].tolist()\n",
    "lte = test[\"comment_text\"].tolist()\n",
    "for i in ltr:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_train_data.append(xx)\n",
    "for i in lte:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_test_data.append(xx)\n",
    "train[\"new_comment_text\"] = new_train_data\n",
    "test[\"new_comment_text\"] = new_test_data\n",
    "\n",
    "trate = train[\"new_comment_text\"].tolist()\n",
    "tete = test[\"new_comment_text\"].tolist()\n",
    "for i, c in enumerate(trate):\n",
    "    trate[i] = re.sub('[^a-zA-Z ?!]+', '', str(trate[i]).lower())\n",
    "for i, c in enumerate(tete):\n",
    "    tete[i] = re.sub('[^a-zA-Z ?!]+', '', tete[i])\n",
    "train[\"comment_text\"] = trate\n",
    "test[\"comment_text\"] = tete\n",
    "del trate, tete\n",
    "train.drop([\"new_comment_text\"], axis=1, inplace=True)\n",
    "test.drop([\"new_comment_text\"], axis=1, inplace=True)\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312735,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    min_df = 2,\n",
    "    stop_words = 'english',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 3),\n",
    "    max_features=30000\n",
    "    )\n",
    "    \n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    min_df = 2,\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=30000)\n",
    "\n",
    "vectorizer = make_union(word_vectorizer, char_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 60000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(all_text)\n",
    "train_features = vectorizer.transform(train_text)\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 60000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "save_variable_pickle(train_features, 'train_features_save')\n",
    "save_variable_pickle(test_features, 'test_features_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "test_features = load_variable_pickle('test_features_save.pickle')\n",
    "train_features = load_variable_pickle('train_features_save.pickle')\n",
    "#clf = load_variable_pickle('_logistic_model5.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 60000) (159571, 60000)\n"
     ]
    }
   ],
   "source": [
    "print(test_features.shape, train_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_A, train_feature_B, train_feature_targetA, train_feature_targetB =\n",
    "    train_test_split(train_feature, train_target, test_size = 0.5, random_state =1023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=200)\n",
    "#gbm.fit(meta_train_toxic_prediction, meta_train_toxic_valid,\n",
    " #       eval_metric='auc')\n",
    "\n",
    "log_model = LogisticRegression(solver='sag')\n",
    "svc_model = LinearSVC(random_state=1023)\n",
    "type(log_model)\n",
    "os.path.exists('/home/yichen/Desktop/toxic/_logistic_model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(train, target, K, random_state ,model):\n",
    "    acc = []\n",
    "    row = train.shape[0]\n",
    "    if row != target.shape[0]:\n",
    "        raise ValueError(\"At least one array required as input\")\n",
    "    num_per_fold = np.int(np.ceil(train.shape[0]/K))\n",
    "    x_train, x_fold, y_train, y_fold1 = train_test_split(train, target, test_size = num_per_fold, random_state = random_state)\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_fold)\n",
    "    acc.append(roc_auc_score(y_fold1, pred))\n",
    "    #print(\"accuracy is {}\".format(accuracy_score(y_fold1, pred)))\n",
    "    i = 1\n",
    "    if train.size != row:\n",
    "        while i < K:\n",
    "            if i != K - 1:\n",
    "                x_fold = train[num_per_fold * i: num_per_fold * (i + 1), :]\n",
    "                y_fold = target[num_per_fold * i: num_per_fold * (i + 1)]\n",
    "                x_train = vstack([train[0: num_per_fold * i, : ], train[num_per_fold * (i + 1): , :]])\n",
    "                y_train = pd.concat([target[0 : num_per_fold * i], target[num_per_fold * (i + 1): ]])\n",
    "                #print(\"x_train: {}, y_train: {}, x_fold: {}, y_fold: {}\".format(x_train.shape, y_train.shape, x_fold.shape, y_fold.shape))\n",
    "            elif i == K-1:\n",
    "                x_fold = train[num_per_fold * i: , :]\n",
    "                y_fold = target[num_per_fold * i: ]\n",
    "                x_train = train[0:num_per_fold * i, :]\n",
    "                y_train = target[0:num_per_fold * i]\n",
    "                \n",
    "            \n",
    "            y_fold1 = pd.concat([y_fold1[:], y_fold[:]])\n",
    "            model.fit(x_train, y_train)\n",
    "            pred1 = model.predict(x_fold)\n",
    "            acc.append(roc_auc_score(y_fold, pred1))\n",
    "            #rint(\"accuracy is {}\".format(accuracy_score(y_fold, pred1)))\n",
    "            pred = np.concatenate((pred, pred1), axis = 0)\n",
    "            i = i + 1\n",
    "    print(\"average roc_auc_score is: {}  for model type: {} \".format(np.mean(acc), type(model)))\n",
    "    return pred# pred_all_testep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_level_models = []\n",
    "scores_auc = []\n",
    "#submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "y_fold_validation = load_variable_pickle('y_fold_validation.pickle')\n",
    "#submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "MNB = MultinomialNB()\n",
    "\n",
    "neigh2 = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh4 = KNeighborsClassifier(n_neighbors=4)\n",
    "neigh8 = KNeighborsClassifier(n_neighbors=8)\n",
    "neigh16 = KNeighborsClassifier(n_neighbors=16)\n",
    "neigh32 = KNeighborsClassifier(n_neighbors=32)\n",
    "neigh64 = KNeighborsClassifier(n_neighbors=64)\n",
    "neigh128 = KNeighborsClassifier(n_neighbors=128)\n",
    "neigh256 = KNeighborsClassifier(n_neighbors=256)\n",
    "neigh512 = KNeighborsClassifier(n_neighbors=512)\n",
    "neigh1024 = KNeighborsClassifier(n_neighbors=1024)\n",
    "\n",
    "etc_levelone = ExtraTreesClassifier(n_estimators= 50, verbose = True, random_state=11)\n",
    "ada = AdaBoostClassifier(n_estimators=100) #verbose = True)\n",
    "\n",
    "rfc= RandomForestClassifier(n_estimators= 5, random_state=11, verbose = True)\n",
    "#gdc = GradientBoostingClassifier(n_estimators=100, validation_fraction=0.2,\n",
    "#                                 tol = 0.01, no_iter_no_change = 5,learning_rate=0.1, random_state=1023)\n",
    "\n",
    "lgb_lvl1 = gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=150) #device = 'gpu', gpu_use_dp = true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/yichen/Desktop/toxic/base_model/_toxic_<class 'sklearn.svm.classes.LinearSVC'>cv_.pickle\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name1 = '/home/yichen/Desktop/toxic/base_model/' + '_' + 'toxic' + '_' + str(type(svc_model)) + 'cv'+ '_'+ '.pickle'\n",
    "name1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(name1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready_for_leveltwo(models, train_data, test_data, _train_target, meta_model):\n",
    "    #os_load_file_path = '/home/yichen/Desktop/toxic/base_model/'\n",
    "    submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "    for class_name in class_names:\n",
    "        os_load_file_path = '/home/yichen/Desktop/toxic/base_model/'\n",
    "        os_load_submission_path = '/home/yichen/Desktop/toxic/submission/'\n",
    "        os_load_submission_path = os_load_file_path + str(class_name) + str(type(meta_model))\n",
    "        os_load_file_path = os_load_file_path + str(class_name) + '/'\n",
    "        print(os_load_file_path)\n",
    "        count = 0\n",
    "        class_counter = 0\n",
    "        train_target = train[class_name]\n",
    "        for model in models:\n",
    "            name = os_load_file_path + '_' + class_name + '_' + str(type(model)) + 'cv'+ '_'+ '.pickle'\n",
    "            if count == 0:\n",
    "                if os.path.exists(name):\n",
    "                    with open(name, 'rb') as f:\n",
    "                        meta_train = pickle.load(f)\n",
    "                    print(\"old prediction stored: {}, shape: {}\".format(type(model), meta_train.shape))\n",
    "                else:\n",
    "                    meta_train = cv_split(train = train_data, target=train_target, K = 5, random_state=1023, model = model)\n",
    "                    with open(name, 'wb') as f:\n",
    "                        pickle.dump(meta_train, f, pickle.HIGHEST_PROTOCOL)\n",
    "                count = count + 1\n",
    "            else:\n",
    "                if os.path.exists(name):\n",
    "                    with open(name, 'rb') as f:\n",
    "                        temp = pickle.load(f)\n",
    "                    print(\"old prediction stored: {}, shape: {}\".format(type(model), temp.shape))\n",
    "                else:\n",
    "                    temp = cv_split(train = train_data, target=train_target, K = 5, random_state=1023, model = model)\n",
    "                    with open(name, 'wb') as f:\n",
    "                        pickle.dump(temp, f, pickle.HIGHEST_PROTOCOL)\n",
    "                meta_train = np.column_stack((meta_train, temp))\n",
    "                count = count + 1\n",
    "                \n",
    "        count = 0                \n",
    "        print(\"cv finished\")\n",
    "        for model in models:\n",
    "            name = os_load_file_path + '_' + class_name + '_' + str(type(model)) + 'base_lvl' + '_' + '.pickle'\n",
    "            if count == 0:\n",
    "                if os.path.exists(name):\n",
    "                    with open(name, 'rb') as f:\n",
    "                        meta_test = pickle.load(f)\n",
    "                    print(\"old prediction stored: {}, shape: {}\".format(type(model), meta_train.shape))\n",
    "                else:\n",
    "                    model.fit(train_data, train_target)\n",
    "                    meta_test = model.predict(test_data)\n",
    "                    with open(name, 'wb') as f:\n",
    "                        pickle.dump(meta_test, f, pickle.HIGHEST_PROTOCOL)\n",
    "                    print(\"model finish predication: {}\".format(str(type(model))))\n",
    "                count = count + 1\n",
    "            else:\n",
    "                if os.path.exists(name):\n",
    "                    with open(name, 'rb') as f:\n",
    "                        temp = pickle.load(f)\n",
    "                    print(\"old prediction stored: {}, shape: {}\".format(type(model), meta_train.shape))\n",
    "                else:\n",
    "                    model.fit(train_data, train_target)\n",
    "                    temp = model.predict(test_data)\n",
    "                    with open(name, 'wb') as f:\n",
    "                        pickle.dump(temp, f, pickle.HIGHEST_PROTOCOL)\n",
    "                    print(\"model finish predication: {}\".format(str(type(model))))\n",
    "                meta_test = np.column_stack((meta_test, temp))\n",
    "                count = count + 1\n",
    "            \n",
    "        \n",
    "        meta_train_valid = y_fold_validation[:, class_counter]\n",
    "        print(\"meta_train: {}, y_fold: {}, meta_test: {}\".format(meta_train.shape, meta_train_valid.shape, meta_test.shape))\n",
    "        if os.path.exists(os_load_submission_path):\n",
    "            with open(name, 'rb') as f:\n",
    "                        a = pickle.load(f)\n",
    "        \n",
    "        else:\n",
    "            meta_model.fit(meta_train, meta_train_valid) \n",
    "            a = meta_model.predict(meta_test)\n",
    "            with open(name, 'wb') as f:\n",
    "                        pickle.dump(os_load_submission_path, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        print(a.shape)\n",
    "        submission[class_name] = a\n",
    "        class_counter = class_counter + 1\n",
    "        print(\"round: \")\n",
    "    submission.to_csv('submission_final.csv', index=False)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fold_validation[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "nusvc = svm.NuSVC(nu=0.01,random_state = 1023, verbose = True)\n",
    "rfc= RandomForestClassifier(n_estimators= 50, random_state=11, verbose = True)\n",
    "\n",
    "gdc = GradientBoostingClassifier(n_estimators=400, \n",
    " learning_rate = 0.1, max_depth=5, random_state=1023, verbose = True)\n",
    "lgb_lvl1 = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=150) #device = 'gpu', gpu_use_dp = true)\n",
    "gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=1000)\n",
    "model_set1 = []\n",
    "model_set1.append(etc_levelone)\n",
    "model_set1.append(ada)\n",
    "model_set1.append(svc_model)\n",
    "model_set1.append(log_model)\n",
    "model_set1.append(MNB)\n",
    "model_set1.append(lgb_lvl1)\n",
    "model_set1.append(rfc)\n",
    "#model_set1.append(gdc)\n",
    "model_set1.append(nusvc)\n",
    "#model_set1.append(neigh2)\n",
    "#model_set1.append(neigh4)\n",
    "#model_set1.append(neigh8)\n",
    "#model_set1.append(neigh16)\n",
    "#model_set1.append(neigh32)\n",
    "#model_set1.append(neigh64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yichen/Desktop/toxic/base_model/toxic/\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (159571,)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, shape: (159571,)\n",
      "cv finished\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, shape: (159571, 8)\n",
      "meta_train: (159571, 8), y_fold: (159571,), meta_test: (153164, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164,)\n",
      "round: \n",
      "/home/yichen/Desktop/toxic/base_model/severe_toxic/\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (159571,)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, shape: (159571,)\n",
      "cv finished\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, shape: (159571, 8)\n",
      "meta_train: (159571, 8), y_fold: (159571,), meta_test: (153164, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164,)\n",
      "round: \n",
      "/home/yichen/Desktop/toxic/base_model/obscene/\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (159571,)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, shape: (159571,)\n",
      "cv finished\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (159571, 8)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (159571, 8)\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "meta_train1 = ready_for_leveltwo(model_set1, train_features, test_features, y_fold_validation, meta_model=gbm)\n",
    "meta_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set1.append(neigh2)\n",
    "model_set1.append(neigh4)\n",
    "model_set1.append(neigh8)\n",
    "model_set1.append(neigh16)\n",
    "model_set1.append(neigh32)\n",
    "meta_train2 = ready_for_leveltwo(model_set1, train_features, test_features, y_fold_validation, meta_model=gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(train, target, K, random_state ,model):\n",
    "    acc = []\n",
    "    row = train.shape[0]\n",
    "    if row != target.shape[0]:\n",
    "        raise ValueError(\"At least one array required as input\")\n",
    "    num_per_fold = np.int(np.ceil(train.shape[0]/K))\n",
    "    x_train, x_fold, y_train, y_fold1 = train_test_split(train, target, test_size = num_per_fold, random_state = random_state)\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_fold)\n",
    "    acc.append(roc_auc_score(y_fold1, pred))\n",
    "    #print(\"accuracy is {}\".format(accuracy_score(y_fold1, pred)))\n",
    "    i = 1\n",
    "    if train.size != row:\n",
    "        while i < K:\n",
    "            if i != K - 1:\n",
    "                x_fold = train[num_per_fold * i: num_per_fold * (i + 1), :]\n",
    "                y_fold = target[num_per_fold * i: num_per_fold * (i + 1)]\n",
    "                x_train = vstack([train[0: num_per_fold * i, : ], train[num_per_fold * (i + 1): , :]])\n",
    "                y_train = pd.concat([target[0 : num_per_fold * i], target[num_per_fold * (i + 1): ]])\n",
    "                #print(\"x_train: {}, y_train: {}, x_fold: {}, y_fold: {}\".format(x_train.shape, y_train.shape, x_fold.shape, y_fold.shape))\n",
    "            elif i == K-1:\n",
    "                x_fold = train[num_per_fold * i: , :]\n",
    "                y_fold = target[num_per_fold * i: ]\n",
    "                x_train = train[0:num_per_fold * i, :]\n",
    "                y_train = target[0:num_per_fold * i]\n",
    "                \n",
    "            \n",
    "            y_fold1 = pd.concat([y_fold1[:], y_fold[:]])\n",
    "            model.fit(x_train, y_train)\n",
    "            pred1 = model.predict(x_fold)\n",
    "            acc.append(roc_auc_score(y_fold, pred1))\n",
    "            #rint(\"accuracy is {}\".format(accuracy_score(y_fold, pred1)))\n",
    "            pred = np.concatenate((pred, pred1), axis = 0)\n",
    "            i = i + 1\n",
    "    print(\"average roc_auc_score is: {}  for model type: {} \".format(np.mean(acc), type(model)))\n",
    "    return pred# pred_all_testep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_class_cv_mutiple_time(model):\n",
    "    result = np.arange(159571*6).reshape(159571,6)\n",
    "    #all_test_result = np.arange(153164*6).reshape(153164,6)\n",
    "    col = 0\n",
    "    for class_name in class_names:\n",
    "        train_target = train[class_name]\n",
    "        test = test_features\n",
    "        pred1, overall_test_result= cv_split(train = train_features, target = train_target, K = 5, random_state=1023, model=model)\n",
    "        result[:, col] = pred1\n",
    "        all_test_result[:, col] = overall_test_result\n",
    "        #y_fold_result[:, col] = y_fold\n",
    "        col = col + 1\n",
    "        print(\"pred shape: {} and overall_test shape: {} \".format(pred1.shape, all_test_result.shape))\n",
    "    \n",
    "    return result, all_test_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_tune(model, train, train_t):\n",
    "    score_auc = []\n",
    "    for class_name in class_names:\n",
    "        train_target = train_t[class_name]\n",
    "        cv_score = np.mean(cross_val_score(model, train, train_target, cv=3, scoring='roc_auc'))\n",
    "        scores_auc.append(np.abs(cv_score))\n",
    "        print('auc CV score for class {} is {}'.format(class_name, np.abs(cv_score)))\n",
    "    print('overall CV score for class is {}'.format(np.mean(score_auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.19.1.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "#print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5717           44.73m\n",
      "         2           0.5479           42.57m\n",
      "         3           0.5277           41.57m\n",
      "         4           0.5125           40.86m\n",
      "         5           0.4988           40.28m\n",
      "         6           0.4872           39.76m\n",
      "         7           0.4779           39.21m\n",
      "         8           0.4672           38.60m\n",
      "         9           0.4593           38.06m\n",
      "        10           0.4504           37.46m\n",
      "        20           0.3956           32.89m\n",
      "        30           0.3636           28.67m\n",
      "        40           0.3433           24.65m\n",
      "        50           0.3272           20.54m\n",
      "        60           0.3151           16.48m\n"
     ]
    }
   ],
   "source": [
    "gdc_max_depth = [3, 5, 7, 10]\n",
    "for max_d in gdc_max_depth:\n",
    "    gdc = GradientBoostingClassifier(n_estimators=100,# validation_fraction=0.2,\n",
    "     learning_rate = 0.1, max_depth=max_d, random_state=1023, verbose = True)\n",
    "    param_tune(gdc, train_features, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 2)\n"
     ]
    }
   ],
   "source": [
    "scores_auc = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "#classifier = LogisticRegression()\n",
    "#for class_name in class_names:\n",
    "train_target = train['toxic']\n",
    "    #print(train_target.shape)\n",
    "classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    #cv_score = np.mean(cross_val_score(\n",
    "     #   classifier, train_features, train_target, cv=3, scoring='neg_log_loss'))\n",
    "    #scores_auc.append(np.abs(cv_score))\n",
    "    #print('auc CV score for class {} is {}'.format(class_name, np.abs(cv_score)))\n",
    "\n",
    "classifier.fit(train_features, train_target)\n",
    "a = classifier.predict_proba(test_features)\n",
    "print(a.shape)\n",
    "a\n",
    "submission[class_name] = a[:, 1]\n",
    "    #save_varible_pickle(classifier, _logistic, model = True)\n",
    "#print('Total auc CV score is {}'.format(np.mean(scores_auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
