{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yichen/anaconda3/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import tensorflow as tf\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy as sp\n",
    "from scipy.sparse import hstack, vstack\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_union\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_variable_pickle(var, name, model = False):\n",
    "    filename = name + '.pickle'\n",
    "    if model:\n",
    "        joblib.dump(var, filename = filename)\n",
    "    else:  \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(var, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_variable_pickle(name, model = False):\n",
    "    filename = name\n",
    "    if model:\n",
    "        return joblib.load(filename = filename)\n",
    "    else:\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_system(os):\n",
    "    if os == 'mac':\n",
    "        train_path = '/Users/yichen/Desktop/toxic/input/train.csv'\n",
    "        test_path = '/Users/yichen/Desktop/toxic/input/test.csv'\n",
    "    elif os == 'linux':\n",
    "        train_path = '/home/yichen/Desktop/toxic/input/train.csv'\n",
    "        test_path = '/home/yichen/Desktop/toxic/input/test.csv'\n",
    "    elif os == 'aws':\n",
    "        train_path = 'train.csv'\n",
    "        test_path = 'test.csv'\n",
    "    \n",
    "    train = pd.read_csv(train_path).fillna(' ')\n",
    "    test = pd.read_csv(test_path).fillna(' ')\n",
    "    return train, test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(true, estimate):\n",
    "    acc = accuracy_score(true, estimate)\n",
    "    logloss = log_loss(true, estimate)\n",
    "    auc = roc_auc_score(true, esimate)\n",
    "    print(\"accuracy score: {}, logloss: {}, auc: {}\".format(acc, logloss, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = choose_system('linux')\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = {\n",
    "    \"&lt;3\": \" good \", \":d\": \" good \",\n",
    "    \":dd\": \" good \",\n",
    "    \":p\": \" good \",\n",
    "    \"8)\": \" good \",\n",
    "    \":-)\": \" good \",\n",
    "    \":)\": \" good \",\n",
    "    \";)\": \" good \",\n",
    "    \"(-:\": \" good \",\n",
    "    \"(:\": \" good \",\n",
    "    \"yay!\": \" good \",\n",
    "    \"yay\": \" good \",\n",
    "    \"yaay\": \" good \",\n",
    "    \"yaaay\": \" good \",\n",
    "    \"yaaaay\": \" good \",\n",
    "    \"yaaaaay\": \" good \",\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" bad \",\n",
    "    \":(\": \" bad \",\n",
    "    \":s\": \" bad \",\n",
    "    \":-s\": \" bad \",\n",
    "    \"&lt;3\": \" heart \",\n",
    "    \":d\": \" smile \",\n",
    "    \":p\": \" smile \",\n",
    "    \":dd\": \" smile \",\n",
    "    \"8)\": \" smile \",\n",
    "    \":-)\": \" smile \",\n",
    "    \":)\": \" smile \",\n",
    "    \";)\": \" smile \",\n",
    "    \"(-:\": \" smile \",\n",
    "    \"(:\": \" smile \",\n",
    "    \":/\": \" worry \",\n",
    "    \":&gt;\": \" angry \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" sad \",\n",
    "    \":(\": \" sad \",\n",
    "    \":s\": \" sad \",\n",
    "    \":-s\": \" sad \",\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\",\n",
    "    r\"\\bdon't\\b\": \"do not\",\n",
    "    r\"\\bdoesn't\\b\": \"does not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bcan't\\b\": \"can not\",\n",
    "    r\"\\bcannot\\b\": \"can not\",\n",
    "    r\"\\bi'm\\b\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"r\": \"are\",\n",
    "    \"u\": \"you\",\n",
    "    \"haha\": \"ha\",\n",
    "    \"hahaha\": \"ha\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"cannot\": \"can not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"i'll\" : \"i will\",\n",
    "    \"its\" : \"it is\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"'s\" : \" is\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"weren't\" : \"were not\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [i for i in repl.keys()]\n",
    "\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "ltr = train[\"comment_text\"].tolist()\n",
    "keys = [i for i in repl.keys()]\n",
    "\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "ltr = train[\"comment_text\"].tolist()\n",
    "lte = test[\"comment_text\"].tolist()\n",
    "for i in ltr:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_train_data.append(xx)\n",
    "for i in lte:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_test_data.append(xx)\n",
    "train[\"new_comment_text\"] = new_train_data\n",
    "test[\"new_comment_text\"] = new_test_data\n",
    "\n",
    "trate = train[\"new_comment_text\"].tolist()\n",
    "tete = test[\"new_comment_text\"].tolist()\n",
    "for i, c in enumerate(trate):\n",
    "    trate[i] = re.sub('[^a-zA-Z ?!]+', '', str(trate[i]).lower())\n",
    "for i, c in enumerate(tete):\n",
    "    tete[i] = re.sub('[^a-zA-Z ?!]+', '', tete[i])\n",
    "train[\"comment_text\"] = trate\n",
    "test[\"comment_text\"] = tete\n",
    "del trate, tete\n",
    "train.drop([\"new_comment_text\"], axis=1, inplace=True)\n",
    "test.drop([\"new_comment_text\"], axis=1, inplace=True)\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312735,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    min_df = 2,\n",
    "    stop_words = 'english',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 3),\n",
    "    max_features=30000\n",
    "    )\n",
    "    \n",
    "\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    min_df = 2,\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=30000)\n",
    "\n",
    "vectorizer = make_union(word_vectorizer, char_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 60000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(all_text)\n",
    "train_features = vectorizer.transform(train_text)\n",
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = vectorizer.transform(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 60000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "save_variable_pickle(train_features, 'train_features_save')\n",
    "save_variable_pickle(test_features, 'test_features_save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "test_features = load_variable_pickle('test_features_save.pickle')\n",
    "train_features = load_variable_pickle('train_features_save.pickle')\n",
    "y_fold_renew = load_variable_pickle('y_fold_renew.pickle')\n",
    "#clf = load_variable_pickle('_logistic_model5.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 60000) (159571, 60000) (159571, 6)\n"
     ]
    }
   ],
   "source": [
    "print(test_features.shape, train_features.shape, y_fold_renew.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_K_fold(train, target, K, model):\n",
    "    acc = []\n",
    "    kf = KFold(n_splits=K, random_state=1023)\n",
    "    count = 0\n",
    "    for train_index, test_index in kf.split(train, target):\n",
    "        X_train, X_test = train[train_index], train[test_index]\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "        #print(\"x_train: {}, x_test: {}, y_train: {}, y_test: {}\". format(X_train.shape, X_test.shape, y_train.shape, y_test.shape))\n",
    "        model.fit(X_train, y_train)\n",
    "        if count == 0:\n",
    "            pred = model.predict(X_test)\n",
    "            y_fold_valid = y_test\n",
    "            acc.append(roc_auc_score(pred, y_test))\n",
    "        else:\n",
    "            pred1 = model.predict(X_test)\n",
    "            pred = np.concatenate((pred, pred1), axis = 0)\n",
    "            #y_fold_valid = np.concatenate((y_fold_valid, y_test))\n",
    "            #print(roc_auc_score(pred1, y_test))\n",
    "            acc.append(roc_auc_score(pred1, y_test))\n",
    "        count = count + 1\n",
    "        #print(\"y_fold_valid.shape: \", y_fold_validation.shape, \"pred.shape: \", pred.shape)\n",
    "    print(\"average roc_auc_score for model: {} is: {}  for model type: {} \".format(str(type(model)), np.mean(acc), type(model)))\n",
    "    #y_fold_name = 'y_fold_valid' + str(type(model))\n",
    "    #save_variable_pickle(y_fold_valid, y_fold_name)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready_for_leveltwo(models, train_data, test_data, target,y_fold, meta_model):\n",
    "    #os_load_file_path = '/home/yichen/Desktop/toxic/base_model/'\n",
    "    class_counter = 0\n",
    "    submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "    for class_name in class_names:\n",
    "        os_load_file_path = '/home/yichen/Desktop/toxic/base_model/'\n",
    "        os_load_submission_path = '/home/yichen/Desktop/toxic/submission/'\n",
    "        os_load_submission_path = os_load_file_path + str(class_name) + str(type(meta_model))\n",
    "        os_load_file_path = os_load_file_path + str(class_name) + '/'\n",
    "        print(os_load_file_path)\n",
    "        count = 0\n",
    "        train_target = target[class_name]\n",
    "        for model in models:\n",
    "            name = os_load_file_path + '_' + class_name + '_' + str(type(model)) + 'cv'+ '_'+ '.pickle'\n",
    "            if count == 0:\n",
    "                if os.path.exists(name):\n",
    "                    with open(name, 'rb') as f:\n",
    "                        meta_train = pickle.load(f)\n",
    "                    print(\"old prediction stored: {}, shape: {}\".format(type(model), meta_train.shape))\n",
    "                else:\n",
    "                    meta_train = split_K_fold(train_data, train_target, 5, model)\n",
    "                   # cv_split(train = train_data, target=train_target, K = 5, random_state=1023, model = model)\n",
    "                    with open(name, 'wb') as f:\n",
    "                        pickle.dump(meta_train, f, pickle.HIGHEST_PROTOCOL)\n",
    "                count = count + 1\n",
    "            else:\n",
    "                if os.path.exists(name):\n",
    "                    with open(name, 'rb') as f:\n",
    "                        temp = pickle.load(f)\n",
    "                    print(\"old prediction stored: {}, shape: {}\".format(type(model), temp.shape))\n",
    "                else:\n",
    "                    temp = split_K_fold(train_data, train_target, 5, model)\n",
    "                    with open(name, 'wb') as f:\n",
    "                        pickle.dump(temp, f, pickle.HIGHEST_PROTOCOL)\n",
    "                meta_train = np.column_stack((meta_train, temp))\n",
    "                count = count + 1\n",
    "                \n",
    "        count = 0                \n",
    "        print(\"cv finished\")\n",
    "        for model in models:\n",
    "            #print(\"count\", count)\n",
    "            name = os_load_file_path + '_' + class_name + '_' + str(type(model)) + 'base_lvl' + '_' + '.pickle'\n",
    "            #print(train_target.shape)\n",
    "            \n",
    "            if count == 0:\n",
    "                if os.path.exists(name):\n",
    "                    with open(name, 'rb') as f:\n",
    "                        meta_test = pickle.load(f)\n",
    "                        print(\"meta_test:\",meta_test.shape)\n",
    "                    print(\"old prediction stored: {}, shape: {}\".format(type(model), meta_train.shape))\n",
    "                else:\n",
    "                    model.fit(train_data, train_target)\n",
    "                    meta_test = model.predict(test_data)\n",
    "                    print(meta_test.shape)\n",
    "                    with open(name, 'wb') as f:\n",
    "                        pickle.dump(meta_test, f, pickle.HIGHEST_PROTOCOL)\n",
    "                    print(\"model finish predication: {}\".format(str(type(model))))\n",
    "                count = count + 1\n",
    "            else:\n",
    "                if os.path.exists(name):\n",
    "                    with open(name, 'rb') as f:\n",
    "                        temp = pickle.load(f)\n",
    "                    print(\"old prediction stored: {}, shape: {}\".format(type(model), meta_train.shape))\n",
    "                    print(temp.shape)\n",
    "                else:\n",
    "                    model.fit(train_data, train_target)\n",
    "                    temp = model.predict(test_data)\n",
    "                    with open(name, 'wb') as f:\n",
    "                        pickle.dump(temp, f, pickle.HIGHEST_PROTOCOL)\n",
    "                    print(\"model finish predication: {}\".format(str(type(model))))\n",
    "                    print(temp.shape)\n",
    "                print(\"meta_test: \", meta_test.shape, \"model: \", str(type(model)))\n",
    "                meta_test = np.column_stack((meta_test, temp))\n",
    "                #print(\"meta_test: \",meta_test.shape)\n",
    "                count = count + 1\n",
    "    \n",
    "            \n",
    "        \n",
    "        meta_train_valid = y_fold[:, class_counter]\n",
    "        #print(\"meta_train: {}, y_fold: {}, meta_test: {}\".format(meta_train.shape, meta_train_valid.shape, meta_test.shape))\n",
    "        if os.path.exists(os_load_submission_path):\n",
    "            with open(name, 'rb') as f:\n",
    "                        a = pickle.load(f)\n",
    "        \n",
    "        else:\n",
    "            meta_model.fit(meta_train, meta_train_valid) \n",
    "            a = meta_model.predict(meta_test)\n",
    "            with open(name, 'wb') as f:\n",
    "                        pickle.dump(os_load_submission_path, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "        print(a.shape)\n",
    "        submission[class_name] = a\n",
    "        class_counter = class_counter + 1\n",
    "        print(\"round: \")\n",
    "    submission.to_csv('submission_final.csv', index=False)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "nusvc = svm.NuSVC(nu=0.01,random_state = 1023, verbose = True)\n",
    "#rfc= RandomForestClassifier(n_estimators= 50, random_state=11, verbose = True)\n",
    "#submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "MNB = MultinomialNB()\n",
    "gdc = GradientBoostingClassifier(n_estimators=400, \n",
    " learning_rate = 0.1, max_depth=5, random_state=1023, verbose = True)\n",
    "gbm_tune = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc', max_depth=12, min_data_in_leaf = 50, num_iterations = 100, \n",
    "                              learning_rate = 0.1\n",
    "                              , device = 'gpu')\n",
    "gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=500, device = 'gpu')\n",
    "etc = ExtraTreesClassifier(n_estimators=200, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "log_model = LogisticRegression(solver='sag')\n",
    "svc_model = LinearSVC(random_state=1023)\n",
    "\n",
    "model_set1 = []\n",
    "model_set1.append(svc_model)\n",
    "model_set1.append(log_model)\n",
    "model_set1.append(MNB)\n",
    "model_set1.append(etc)\n",
    "#model_set1.append(ada)\n",
    "model_set1.append(gbm_tune)\n",
    "model_set1.append(rfc)\n",
    "#model_set1.append(gdc)\n",
    "model_set1.append(nusvc)\n",
    "#model_set1.append(neigh2)\n",
    "#model_set1.append(neigh4)\n",
    "#model_set1.append(neigh8)\n",
    "#model_set1.append(neigh16)\n",
    "#model_set1.append(neigh32)\n",
    "#model_set1.append(neigh64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yichen/Desktop/toxic/base_model/toxic/\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (159571,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, shape: (159571,)\n",
      "cv finished\n",
      "meta_test: (153164,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (159571, 7)\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (159571, 7)\n",
      "(153164,)\n",
      "meta_test:  (153164,) model:  <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (159571, 7)\n",
      "(153164,)\n",
      "meta_test:  (153164, 2) model:  <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (159571, 7)\n",
      "(153164,)\n",
      "meta_test:  (153164, 3) model:  <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (159571, 7)\n",
      "(153164,)\n",
      "meta_test:  (153164, 4) model:  <class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (159571, 7)\n",
      "(153164,)\n",
      "meta_test:  (153164, 5) model:  <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, shape: (159571, 7)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-23e35d979aa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeta_train1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mready_for_leveltwo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_set1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_fold_renew\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmeta_train1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-e76cb9fed9af>\u001b[0m in \u001b[0;36mready_for_leveltwo\u001b[0;34m(models, train_data, test_data, target, y_fold, meta_model)\u001b[0m\n\u001b[1;32m     62\u001b[0m                         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"old prediction stored: {}, shape: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "meta_train1 = ready_for_leveltwo(model_set1, train_data=train_features, test_data=test_features, target=train,y_fold=y_fold_renew, meta_model=gbm)\n",
    "meta_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set1.append(neigh2)\n",
    "model_set1.append(neigh4)\n",
    "model_set1.append(neigh8)\n",
    "model_set1.append(neigh16)\n",
    "model_set1.append(neigh32)\n",
    "meta_train2 = ready_for_leveltwo(model_set1, train_features, test_features, y_fold_validation, meta_model=gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(train, target, K, random_state ,model):\n",
    "    acc = []\n",
    "    row = train.shape[0]\n",
    "    if row != target.shape[0]:\n",
    "        raise ValueError(\"At least one array required as input\")\n",
    "    num_per_fold = np.int(np.ceil(train.shape[0]/K))\n",
    "    x_train, x_fold, y_train, y_fold1 = train_test_split(train, target, test_size = num_per_fold, random_state = random_state)\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_fold)\n",
    "    acc.append(roc_auc_score(y_fold1, pred))\n",
    "    #print(\"accuracy is {}\".format(accuracy_score(y_fold1, pred)))\n",
    "    i = 1\n",
    "    if train.size != row:\n",
    "        while i < K:\n",
    "            if i != K - 1:\n",
    "                x_fold = train[num_per_fold * i: num_per_fold * (i + 1), :]\n",
    "                y_fold = target[num_per_fold * i: num_per_fold * (i + 1)]\n",
    "                x_train = vstack([train[0: num_per_fold * i, : ], train[num_per_fold * (i + 1): , :]])\n",
    "                y_train = pd.concat([target[0 : num_per_fold * i], target[num_per_fold * (i + 1): ]])\n",
    "                #print(\"x_train: {}, y_train: {}, x_fold: {}, y_fold: {}\".format(x_train.shape, y_train.shape, x_fold.shape, y_fold.shape))\n",
    "            elif i == K-1:\n",
    "                x_fold = train[num_per_fold * i: , :]\n",
    "                y_fold = target[num_per_fold * i: ]\n",
    "                x_train = train[0:num_per_fold * i, :]\n",
    "                y_train = target[0:num_per_fold * i]\n",
    "                \n",
    "            \n",
    "            y_fold1 = pd.concat([y_fold1[:], y_fold[:]])\n",
    "            model.fit(x_train, y_train)\n",
    "            pred1 = model.predict(x_fold)\n",
    "            acc.append(roc_auc_score(y_fold, pred1))\n",
    "            #rint(\"accuracy is {}\".format(accuracy_score(y_fold, pred1)))\n",
    "            pred = np.concatenate((pred, pred1), axis = 0)\n",
    "            i = i + 1\n",
    "    print(\"average roc_auc_score is: {}  for model type: {} \".format(np.mean(acc), type(model)))\n",
    "    return pred# pred_all_testep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_class_cv_mutiple_time(model):\n",
    "    result = np.arange(159571*6).reshape(159571,6)\n",
    "    #all_test_result = np.arange(153164*6).reshape(153164,6)\n",
    "    col = 0\n",
    "    for class_name in class_names:\n",
    "        train_target = train[class_name]\n",
    "        test = test_features\n",
    "        pred1, overall_test_result= cv_split(train = train_features, target = train_target, K = 5, random_state=1023, model=model)\n",
    "        result[:, col] = pred1\n",
    "        all_test_result[:, col] = overall_test_result\n",
    "        #y_fold_result[:, col] = y_fold\n",
    "        col = col + 1\n",
    "        print(\"pred shape: {} and overall_test shape: {} \".format(pred1.shape, all_test_result.shape))\n",
    "    \n",
    "    return result, all_test_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_tune_all_class(model, train, train_t):\n",
    "    score_auc = []\n",
    "    for class_name in class_names:\n",
    "        train_target = train_t[class_name]\n",
    "        cv_score = np.mean(cross_val_score(model, train, train_target, cv=3, scoring='roc_auc'))\n",
    "        scores_auc.append(np.abs(cv_score))\n",
    "        print('auc CV score for class {} is {}'.format(class_name, np.abs(cv_score)))\n",
    "    print('overall CV score for class is {}'.format(np.mean(score_auc)))\n",
    "\n",
    "def param_tune_one_class(model, train, train_target):\n",
    "    cv_score = np.mean(cross_val_score(model, train, train_target, cv=3, scoring='roc_auc'))\n",
    "    print('auc CV score for class is {}'.format(np.abs(cv_score)))\n",
    "    #print('overall CV score for class is {}'.format(np.mean(score_auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.19.1.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "#print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.5312          114.70m\n",
      "         2           0.4968          110.61m\n",
      "         3           0.4737          109.85m\n",
      "         4           0.4500          110.46m\n",
      "         5           0.4324          109.84m\n",
      "         6           0.4175          109.34m\n",
      "         7           0.4033          108.66m\n",
      "         8           0.3902          107.71m\n",
      "         9           0.3824          107.06m\n",
      "        10           0.3750          106.17m\n",
      "        20           0.3124          103.25m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-7c1951a86b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m gdc = GradientBoostingClassifier(n_estimators=150,# validation_fraction=0.2,\n\u001b[1;32m      4\u001b[0m      learning_rate = 0.15, max_depth=5, random_state=1023, verbose = True)\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mparam_tune_one_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'toxic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-6ff7925509b5>\u001b[0m in \u001b[0;36mparam_tune_one_class\u001b[0;34m(model, train, train_target)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparam_tune_one_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mscore_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcv_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mscores_auc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'auc CV score for class is {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX_csc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m                 tree.fit(X_csc, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 785\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gdc_max_depth = [3, 5, 7, 10]\n",
    "#for max_d in gdc_max_depth:\n",
    "gdc = GradientBoostingClassifier(n_estimators=150,# validation_fraction=0.2,\n",
    "     learning_rate = 0.15, max_depth=5, random_state=1023, verbose = True)\n",
    "param_tune_one_class(gdc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  2.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:   23.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:   28.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc CV score for class is 0.9260250228550927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:   30.6s finished\n"
     ]
    }
   ],
   "source": [
    "rfc5 = RandomForestClassifier(n_estimators=200, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "param_tune_one_class(rfc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:   28.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:   29.8s finished\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc CV score for class is 0.9050253348431814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:   19.8s finished\n"
     ]
    }
   ],
   "source": [
    "rfc5 = RandomForestClassifier(n_estimators=200, max_depth = 7, min_samples_leaf= 400, random_state=1023, verbose = True)\n",
    "param_tune_one_class(rfc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/anaconda3/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc CV score for class is 0.9679447925002233\n"
     ]
    }
   ],
   "source": [
    "gbm_tune = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc', max_depth=12, min_data_in_leaf = 50, num_iterations = 100, \n",
    "                              learning_rate = 0.1\n",
    "                              , device = 'gpu')\n",
    "param_tune_one_class(gbm_tune, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc5 = RandomForestClassifier(n_estimators=300, \n",
    "                              max_depth = 7, random_state=1023, verbose = True)\n",
    "param_tune_one_class(rfc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc5 = RandomForestClassifier(n_estimators= 400,max_depth = 7, random_state=1023, verbose = True)\n",
    "param_tune_one_class(rfc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc5 = ExtraTreesClassifier(n_estimators=200, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc5 = ExtraTreesClassifier(n_estimators=200, min_samples_leaf= 400, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc5 = ExtraTreesClassifier(n_estimators=130, min_samples_leaf= 400, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc5 = ExtraTreesClassifier(n_estimators=400, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc5 = ExtraTreesClassifier(n_estimators=600, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdc = GradientBoostingClassifier(n_estimators=200,# validation_fraction=0.2,\n",
    "     learning_rate = 0.15, max_depth=5, random_state=1023, verbose = True)\n",
    "param_tune_one_class(gdc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdc = GradientBoostingClassifier(n_estimators=200,# validation_fraction=0.2,\n",
    "     learning_rate = 0.15, max_depth=7, random_state=1023, verbose = True)\n",
    "param_tune_one_class(gdc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdc = GradientBoostingClassifier(n_estimators=200,# validation_fraction=0.2,\n",
    "     learning_rate = 0.15, max_depth=10, random_state=1023, verbose = True)\n",
    "param_tune_one_class(gdc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM]auc CV score for class is 0.9179922166947202\n"
     ]
    }
   ],
   "source": [
    "param_tune_one_class(nusvc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 2)\n"
     ]
    }
   ],
   "source": [
    "scores_auc = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "#classifier = LogisticRegression()\n",
    "#for class_name in class_names:\n",
    "train_target = train['toxic']\n",
    "    #print(train_target.shape)\n",
    "classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    #cv_score = np.mean(cross_val_score(\n",
    "     #   classifier, train_features, train_target, cv=3, scoring='neg_log_loss'))\n",
    "    #scores_auc.append(np.abs(cv_score))\n",
    "    #print('auc CV score for class {} is {}'.format(class_name, np.abs(cv_score)))\n",
    "\n",
    "classifier.fit(train_features, train_target)\n",
    "a = classifier.predict_proba(test_features)\n",
    "print(a.shape)\n",
    "a\n",
    "submission[class_name] = a[:, 1]\n",
    "    #save_varible_pickle(classifier, _logistic, model = True)\n",
    "#print('Total auc CV score is {}'.format(np.mean(scores_auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_split(train, target, K, random_state ,model):\n",
    "    acc = []\n",
    "    row = train.shape[0]\n",
    "    if row != target.shape[0]:\n",
    "        raise ValueError(\"At least one array required as input\")\n",
    "    num_per_fold = np.int(np.ceil(train.shape[0]/K))\n",
    "    x_train, x_fold, y_train, y_fold1 = train_test_split(train, target, test_size = num_per_fold, random_state = random_state)\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_fold)\n",
    "    acc.append(roc_auc_score(y_fold1, pred))\n",
    "    #print(\"accuracy is {}\".format(accuracy_score(y_fold1, pred)))\n",
    "    i = 1\n",
    "    if train.size != row:\n",
    "        while i < K:\n",
    "            if i != K - 1:\n",
    "                x_fold = train[num_per_fold * i: num_per_fold * (i + 1), :]\n",
    "                y_fold = target[num_per_fold * i: num_per_fold * (i + 1)]\n",
    "                x_train = vstack([train[0: num_per_fold * i, : ], train[num_per_fold * (i + 1): , :]])\n",
    "                y_train = pd.concat([target[0 : num_per_fold * i], target[num_per_fold * (i + 1): ]])\n",
    "                #print(\"x_train: {}, y_train: {}, x_fold: {}, y_fold: {}\".format(x_train.shape, y_train.shape, x_fold.shape, y_fold.shape))\n",
    "            elif i == K-1:\n",
    "                x_fold = train[num_per_fold * i: , :]\n",
    "                y_fold = target[num_per_fold * i: ]\n",
    "                x_train = train[0:num_per_fold * i, :]\n",
    "                y_train = target[0:num_per_fold * i]\n",
    "                \n",
    "            \n",
    "            y_fold1 = pd.concat([y_fold1[:], y_fold[:]])\n",
    "            model.fit(x_train, y_train)\n",
    "            pred1 = model.predict(x_fold)\n",
    "            acc.append(roc_auc_score(y_fold, pred1))\n",
    "            #rint(\"accuracy is {}\".format(accuracy_score(y_fold, pred1)))\n",
    "            pred = np.concatenate((pred, pred1), axis = 0)\n",
    "            i = i + 1\n",
    "    print(\"average roc_auc_score is: {}  for model type: {} \".format(np.mean(acc), type(model)))\n",
    "    return pred# pred_all_testep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
