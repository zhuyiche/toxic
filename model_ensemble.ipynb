{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/usr/bin/python3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as K\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy as sp\n",
    "from scipy.sparse import hstack, vstack\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_union\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_variable_pickle(var, name, model = False):\n",
    "    filename = name + '.pickle'\n",
    "    if model:\n",
    "        joblib.dump(var, filename = filename)\n",
    "    else:  \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(var, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_variable_pickle(name, model = False):\n",
    "    filename = name\n",
    "    if model:\n",
    "        return joblib.load(filename = filename)\n",
    "    else:\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_system(os):\n",
    "    if os == 'mac':\n",
    "        train_path = '/Users/yichen/Desktop/toxic/input/train.csv'\n",
    "        test_path = '/Users/yichen/Desktop/toxic/input/test.csv'\n",
    "    elif os == 'linux':\n",
    "        train_path = '/home/yichen/Desktop/toxic/input/train.csv'\n",
    "        test_path = '/home/yichen/Desktop/toxic/input/test.csv'\n",
    "    elif os == 'aws':\n",
    "        train_path = 'train.csv'\n",
    "        test_path = 'test.csv'\n",
    "    \n",
    "    train = pd.read_csv(train_path).fillna(' ')\n",
    "    test = pd.read_csv(test_path).fillna(' ')\n",
    "    return train, test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(true, estimate):\n",
    "    acc = accuracy_score(true, estimate)\n",
    "    logloss = log_loss(true, estimate)\n",
    "    auc = roc_auc_score(true, esimate)\n",
    "    print(\"accuracy score: {}, logloss: {}, auc: {}\".format(acc, logloss, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = choose_system('linux')\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = {\n",
    "    \"&lt;3\": \" good \", \":d\": \" good \",\n",
    "    \":dd\": \" good \",\n",
    "    \":p\": \" good \",\n",
    "    \"8)\": \" good \",\n",
    "    \":-)\": \" good \",\n",
    "    \":)\": \" good \",\n",
    "    \";)\": \" good \",\n",
    "    \"(-:\": \" good \",\n",
    "    \"(:\": \" good \",\n",
    "    \"yay!\": \" good \",\n",
    "    \"yay\": \" good \",\n",
    "    \"yaay\": \" good \",\n",
    "    \"yaaay\": \" good \",\n",
    "    \"yaaaay\": \" good \",\n",
    "    \"yaaaaay\": \" good \",\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" bad \",\n",
    "    \":(\": \" bad \",\n",
    "    \":s\": \" bad \",\n",
    "    \":-s\": \" bad \",\n",
    "    \"&lt;3\": \" heart \",\n",
    "    \":d\": \" smile \",\n",
    "    \":p\": \" smile \",\n",
    "    \":dd\": \" smile \",\n",
    "    \"8)\": \" smile \",\n",
    "    \":-)\": \" smile \",\n",
    "    \":)\": \" smile \",\n",
    "    \";)\": \" smile \",\n",
    "    \"(-:\": \" smile \",\n",
    "    \"(:\": \" smile \",\n",
    "    \":/\": \" worry \",\n",
    "    \":&gt;\": \" angry \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" sad \",\n",
    "    \":(\": \" sad \",\n",
    "    \":s\": \" sad \",\n",
    "    \":-s\": \" sad \",\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\",\n",
    "    r\"\\bdon't\\b\": \"do not\",\n",
    "    r\"\\bdoesn't\\b\": \"does not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bcan't\\b\": \"can not\",\n",
    "    r\"\\bcannot\\b\": \"can not\",\n",
    "    r\"\\bi'm\\b\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"r\": \"are\",\n",
    "    \"u\": \"you\",\n",
    "    \"haha\": \"ha\",\n",
    "    \"hahaha\": \"ha\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"cannot\": \"can not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"i'll\" : \"i will\",\n",
    "    \"its\" : \"it is\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"'s\" : \" is\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"weren't\" : \"were not\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [i for i in repl.keys()]\n",
    "\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "ltr = train[\"comment_text\"].tolist()\n",
    "keys = [i for i in repl.keys()]\n",
    "\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "ltr = train[\"comment_text\"].tolist()\n",
    "lte = test[\"comment_text\"].tolist()\n",
    "for i in ltr:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_train_data.append(xx)\n",
    "for i in lte:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_test_data.append(xx)\n",
    "train[\"new_comment_text\"] = new_train_data\n",
    "test[\"new_comment_text\"] = new_test_data\n",
    "\n",
    "trate = train[\"new_comment_text\"].tolist()\n",
    "tete = test[\"new_comment_text\"].tolist()\n",
    "for i, c in enumerate(trate):\n",
    "    trate[i] = re.sub('[^a-zA-Z ?!]+', '', str(trate[i]).lower())\n",
    "for i, c in enumerate(tete):\n",
    "    tete[i] = re.sub('[^a-zA-Z ?!]+', '', tete[i])\n",
    "train[\"comment_text\"] = trate\n",
    "test[\"comment_text\"] = tete\n",
    "del trate, tete\n",
    "train.drop([\"new_comment_text\"], axis=1, inplace=True)\n",
    "test.drop([\"new_comment_text\"], axis=1, inplace=True)\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312735,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "test_features = load_variable_pickle('test_features_save.pickle')\n",
    "train_features = load_variable_pickle('train_features_save.pickle')\n",
    "y_fold_renew = load_variable_pickle('y_fold_valid.pickle')\n",
    "#clf = load_variable_pickle('_logistic_model5.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 60000) (159571, 60000) (159571, 6)\n"
     ]
    }
   ],
   "source": [
    "print(test_features.shape, train_features.shape, y_fold_renew.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "meta_valid_y = load_variable_pickle('meta_valid_y.pickle')\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "nusvc = svm.NuSVC(nu=0.005,random_state = 1023, verbose = True)\n",
    "#rfc= RandomForestClassifier(n_estimators= 50, random_state=11, verbose = True)\n",
    "#submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "MNB = MultinomialNB()\n",
    "gdc = GradientBoostingClassifier(n_estimators=400, \n",
    " learning_rate = 0.1, max_depth=5, random_state=1023, verbose = True)\n",
    "gbm_tune = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc', max_depth=12, min_data_in_leaf = 50, num_iterations = 100, \n",
    "                              learning_rate = 0.1)\n",
    "                              #, device = 'gpu')\n",
    "gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=500)# device = 'gpu')\n",
    "etc = ExtraTreesClassifier(n_estimators=200, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "log_model = LogisticRegression(solver='sag')\n",
    "svc_model = LinearSVC(random_state=1023)\n",
    "\n",
    "\n",
    "model_set1 = []\n",
    "model_set1.append(MNB)\n",
    "model_set1.append(svc_model)\n",
    "model_set1.append(log_model)\n",
    "model_set1.append(etc)\n",
    "#model_set1.append(ada)\n",
    "model_set1.append(gbm_tune)\n",
    "model_set1.append(rfc)\n",
    "\n",
    "#model_set1.append(gdc)\n",
    "model_set1.append(nusvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model_set_shallow = []\n",
    "log_model = LogisticRegression(solver='sag')\n",
    "svc_model = LinearSVC(random_state=1023)\n",
    "gbm_s = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc', max_depth = 3, min_data_in_leaf = 50, num_iterations = 100, \n",
    "                              learning_rate = 0.1)\n",
    "MNB = MultinomialNB()\n",
    "etc_s = ExtraTreesClassifier(n_estimators=100, min_samples_leaf= 100, random_state=1023, verbose = True)\n",
    "rfc_s = RandomForestClassifier(n_estimators = 100, min_samples_leaf= 100, random_state=1023, verbose = True)\n",
    "nusvc_s = svm.NuSVC(nu=0.005,random_state = 1023, verbose = True)\n",
    "#cat_boost = CatBoostClassifier()\n",
    "\n",
    "gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=500)\n",
    "#ada = AdaBoostClassifier(n_estimators= 300)\n",
    "model_set_shallow.append(log_model)\n",
    "model_set_shallow.append(MNB)\n",
    "model_set_shallow.append(svc_model)\n",
    "model_set_shallow.append(etc_s)\n",
    "model_set_shallow.append(rfc_s)\n",
    "model_set_shallow.append(gbm_s)\n",
    "#model_set_shallow.append(nusvc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_K_fold(train, target, K, model):\n",
    "    acc = []\n",
    "    kf = KFold(n_splits=K, random_state=1023)\n",
    "    count = 0\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        X_train, X_test = train[train_index], train[test_index]\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        if count == 0:\n",
    "            pred = model.predict(X_test)\n",
    "            #y_fold_valid = y_test\n",
    "            #acc.append(roc_auc_score(pred, y_test))\n",
    "        else:\n",
    "            pred1 = model.predict(X_test)\n",
    "            pred = np.concatenate((pred, pred1), axis = 0)\n",
    "            #y_fold_valid = np.concatenate((y_fold_valid, y_test))\n",
    "            #acc.append(roc_auc_score(pred1, y_test))\n",
    "        count = count + 1\n",
    "    #print(\"average roc_auc_score for model: {} is: {}\".format(str(type(model)), np.mean(acc)))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_meta_gru= load_variable_pickle('base_model/test_meta_gru.pickle')\n",
    "test_meta_lstm = load_variable_pickle('base_model/test_meta_lstm.pickle')\n",
    "gru_y_pred = load_variable_pickle('base_model/gru_y_pred.pickle')\n",
    "lstm_y_pred = load_variable_pickle('base_model/lstm_y_pred.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "y_fold_renew = load_variable_pickle('y_fold_valid.pickle')\n",
    "model_set_shallow = []\n",
    "log_model = LogisticRegression(solver='sag')\n",
    "svc_model = LinearSVC(random_state=1023)\n",
    "gbm_s = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc', max_depth = 3, min_data_in_leaf = 50, num_iterations = 100, \n",
    "                              learning_rate = 0.1)\n",
    "BNB = BernoulliNB()\n",
    "MNB = MultinomialNB()\n",
    "etc_s = ExtraTreesClassifier(n_estimators=100, min_samples_leaf= 100, random_state=1023, verbose = True)\n",
    "rfc_s = RandomForestClassifier(n_estimators = 100, min_samples_leaf= 100, random_state=1023, verbose = True)\n",
    "nusvc_s = svm.NuSVC(nu=0.005,random_state = 1023, verbose = True)\n",
    "#cat_boost = CatBoostClassifier()\n",
    "gdc = GradientBoostingClassifier(n_estimators=400, \n",
    " learning_rate = 0.1, max_depth=5, random_state=1023, verbose = True)\n",
    "\n",
    "gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=500)\n",
    "ada = AdaBoostClassifier(n_estimators= 100)\n",
    "#neigh2 = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "#model_set_shallow.append(ada)\n",
    "model_set_shallow.append(MNB)\n",
    "model_set_shallow.append(log_model)\n",
    "#model_set_shallow.append(BNB)\n",
    "#model_set_shallow.append(MNB)\n",
    "model_set_shallow.append(svc_model)\n",
    "model_set_shallow.append(etc_s)\n",
    "model_set_shallow.append(rfc_s)\n",
    "model_set_shallow.append(gbm_s)\n",
    "model_set_shallow.append(nusvc_s)\n",
    "#model_set_shallow.append(neigh2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model_ada = AdaBoostClassifier(n_estimators= 300)\n",
    "meta_model_gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        num_leaves= 128,\n",
    "                        learning_rate=0.1,\n",
    "                        n_estimators=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_model_pred(models,train_data, test_data, target,y_valid, meta_model):\n",
    "    meta_roc_score = []\n",
    "    \n",
    "    \n",
    "    class_counter = 0\n",
    "    submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "    for class_name in class_names:\n",
    "        os_load_file_path = '/home/yichen/Desktop/toxic/base_model/'\n",
    "        os_load_submission_path = '/home/yichen/Desktop/toxic/submission_valid/'\n",
    "        os_load_submission_path = os_load_file_path + str(class_name) + str(type(meta_model))\n",
    "        os_load_file_path = os_load_file_path + str(class_name) + '/'\n",
    "        print(os_load_file_path)\n",
    "        count = 0\n",
    "        train_target = target[class_name]\n",
    "        for model in models:\n",
    "            name = os_load_file_path +'base_lvl/'+ '_' + class_name + '_' + str(type(model)) + 'base_lvl' + '_' + '.pickle'\n",
    "            if count == 0:\n",
    "                if os.path.exists(name):\n",
    "                    with open(name, 'rb') as f:\n",
    "                        train_meta = pickle.load(f)\n",
    "                    print(\"old prediction stored: {}, shape: {}\".format(type(model), train_meta.shape))\n",
    "                else:\n",
    "                    train_meta = split_K_fold(train_data, train_target, 5, model)\n",
    "                    with open(name, 'wb') as f:\n",
    "                        pickle.dump(train_meta, f, pickle.HIGHEST_PROTOCOL)\n",
    "                count = count + 1\n",
    "            else:\n",
    "                if os.path.exists(name):\n",
    "                    with open(name, 'rb') as f:\n",
    "                        temp = pickle.load(f)\n",
    "                    print(\"old prediction stored: {}, shape: {}\".format(type(model), temp.shape))\n",
    "                else:\n",
    "                    temp = split_K_fold(train_data, train_target, 5, model)\n",
    "                    with open(name, 'wb') as f:\n",
    "                        pickle.dump(temp, f, pickle.HIGHEST_PROTOCOL)\n",
    "                train_meta = np.column_stack((train_meta, temp))\n",
    "                count = count + 1\n",
    "            print(\"train_meta.shape: \",train_meta.shape, \" for class: \", str(type(model)))\n",
    "        #add nn prediction\n",
    "        \n",
    "        \n",
    "        count = 0                \n",
    "        print(\"cv finished\")\n",
    "        for model in models:\n",
    "            #print(\"count\", count)\n",
    "            test_meta_name = os_load_file_path + 'meta_test/' + class_name + '_' + 'test_meta '+ '_' + str(type(model)) + '.pickle'\n",
    "            \n",
    "            if count == 0:\n",
    "                if os.path.exists(test_meta_name):\n",
    "                    with open(test_meta_name, 'rb') as f:\n",
    "                        test_meta = pickle.load(f)\n",
    "                        \n",
    "                    print(\"old prediction stored: {}, test_meta: {}\".format(type(model),test_meta.shape))\n",
    "                else:\n",
    "                    model.fit(train_data, train_target)\n",
    "                    test_meta = model.predict(test_data)\n",
    "\n",
    "                    with open(test_meta_name, 'wb') as f:\n",
    "                        pickle.dump(test_meta, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        \n",
    "                    print(\"model finish predication: {}\".format(str(type(model))))\n",
    "                count = count + 1\n",
    "            else:\n",
    "                if os.path.exists(test_meta_name):\n",
    "                    with open(test_meta_name, 'rb') as f:\n",
    "                        temp_test_meta = pickle.load(f)\n",
    "                        \n",
    "                    print(\"old prediction stored: {}, test_meta: {}\".format(type(model), temp_test_meta.shape))\n",
    "                else:\n",
    "                    model.fit(train_data, train_target)\n",
    "                    temp_test_meta = model.predict(test_data)\n",
    "                    \n",
    "                    with open(test_meta_name, 'wb') as f:\n",
    "                        pickle.dump(temp_test_meta, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        \n",
    "                    print(\"model finish predication: {}\".format(str(type(model))))\n",
    "\n",
    "                test_meta = np.column_stack((test_meta, temp_test_meta))\n",
    "                #print(\"partB_meta: {}, test_meta: {}\".format(partB_meta.shape, test_meta.shape))\n",
    "                count = count + 1\n",
    "        \n",
    "        #test_meta = np.column_stack((test_meta, gru_meta_test[:, class_counter]))\n",
    "        #test_meta = np.column_stack((test_meta, lstm_meta_test[:, class_counter]))\n",
    "        #train_meta = np.column_stack((train_meta, gru_y_pred[:, class_counter]))\n",
    "        #train_meta = np.column_stack((train_meta, lstm_y_pred[:, class_counter]))\n",
    "        #print(\"partA_meta with nn: {} and partB_meta with nn: {}\".format(train_meta.shape, test_meta.shape))\n",
    "        \n",
    "        #save for whole nn meta\n",
    "        if class_counter == 0:\n",
    "            train_meta_allclass = train_meta\n",
    "            test_meta_allclass = test_meta\n",
    "        else:\n",
    "            train_meta_allclass = np.column_stack((train_meta_allclass, train_meta))\n",
    "            test_meta_allclass = np.column_stack((test_meta_allclass, test_meta))\n",
    "        #we needs to take in nn prediction.\n",
    "        #GRU and LSTM for now\n",
    "        \n",
    "        print(\"need this shape: \", train_meta.shape)\n",
    "        meta_train_valid = y_valid[:, class_counter]\n",
    "        #this is for single class\n",
    "        meta_model_name = '/home/yichen/Desktop/toxic/base_model/' + class_name + '/' + 'meta_model_' + str(type(meta_model))\n",
    "        if type(meta_model) == 'keras.models.Sequential':\n",
    "            print(\"meta_model is nn\")\n",
    "            xt, xte, yt, yte = train_test_split(train_data, train_target, train_size=0.9)\n",
    "            RocAuc = RocAucEvaluation(validation_data=(xte, yte), interval=1)\n",
    "            meta_model.fit(xt, yt, epochs = 2, batch_size = 32, verbose = 1, callbacks=[RocAuc])\n",
    "            test_pred = meta_model.predict(test_meta)\n",
    "        else:\n",
    "            if os.path.exists(meta_model_name):\n",
    "                print(\"meta_model same as last time\")\n",
    "                #meta_gbm = load_variable_pickle('meta_model_<class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>.pickle')\n",
    "            else:\n",
    "                print(meta_train_valid.shape, train_meta.shape)\n",
    "                meta_model.fit(train_meta, meta_train_valid)\n",
    "                test_pred = meta_model.predict(test_meta)\n",
    "                #print(\"test_pred: {} \".format(test_pred.shape))\n",
    "                with open(meta_model_name, 'wb') as f:\n",
    "                            pickle.dump(test_pred, f, pickle.HIGHEST_PROTOCOL)\n",
    "                    \n",
    "        submission[class_name] = test_pred\n",
    "        class_counter = class_counter + 1\n",
    "        print(\"round: \")\n",
    "    #save_variable_pickle(partA_meta_allclass, 'partA_meta_allclass')\n",
    "    #save_variable_pickle(partB_meta_allclass, 'partB_meta_allclass')\n",
    "    submission.to_csv('submission_final.csv', index=False)\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yichen/Desktop/toxic/base_model/toxic/\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (159571,)\n",
      "train_meta.shape:  (159571,)  for class:  <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (159571,)\n",
      "train_meta.shape:  (159571, 2)  for class:  <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (159571,)\n",
      "train_meta.shape:  (159571, 3)  for class:  <class 'sklearn.svm.classes.LinearSVC'>\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (159571,)\n",
      "train_meta.shape:  (159571, 4)  for class:  <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (159571,)\n",
      "train_meta.shape:  (159571, 5)  for class:  <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (159571,)\n",
      "train_meta.shape:  (159571, 6)  for class:  <class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, shape: (159571,)\n",
      "train_meta.shape:  (159571, 7)  for class:  <class 'sklearn.svm.classes.NuSVC'>\n",
      "cv finished\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, test_meta: (153164,)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, test_meta: (153164,)\n",
      "need this shape:  (159571, 7)\n",
      "(159571,) (159571, 7)\n",
      "round: \n",
      "/home/yichen/Desktop/toxic/base_model/severe_toxic/\n",
      "train_meta.shape:  (159571,)  for class:  <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "train_meta.shape:  (159571, 2)  for class:  <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "train_meta.shape:  (159571, 3)  for class:  <class 'sklearn.svm.classes.LinearSVC'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_meta.shape:  (159571, 4)  for class:  <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    9.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    9.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.9min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_meta.shape:  (159571, 5)  for class:  <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_meta.shape:  (159571, 6)  for class:  <class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]train_meta.shape:  (159571, 7)  for class:  <class 'sklearn.svm.classes.NuSVC'>\n",
      "cv finished\n",
      "model finish predication: <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "model finish predication: <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "model finish predication: <class 'sklearn.svm.classes.LinearSVC'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   34.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model finish predication: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   38.5s finished\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model finish predication: <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model finish predication: <class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LibSVM]model finish predication: <class 'sklearn.svm.classes.NuSVC'>\n",
      "need this shape:  (159571, 7)\n",
      "(159571,) (159571, 7)\n",
      "round: \n",
      "/home/yichen/Desktop/toxic/base_model/obscene/\n",
      "train_meta.shape:  (159571,)  for class:  <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "train_meta.shape:  (159571, 2)  for class:  <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "train_meta.shape:  (159571, 3)  for class:  <class 'sklearn.svm.classes.LinearSVC'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    9.4s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.1min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    8.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_meta.shape:  (159571, 4)  for class:  <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    9.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.7min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.6min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    7.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.5min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_meta.shape:  (159571, 5)  for class:  <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_meta.shape:  (159571, 6)  for class:  <class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]train_meta.shape:  (159571, 7)  for class:  <class 'sklearn.svm.classes.NuSVC'>\n",
      "cv finished\n",
      "model finish predication: <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "model finish predication: <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "model finish predication: <class 'sklearn.svm.classes.LinearSVC'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-2972e2e17076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                               \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_fold_renew\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                               meta_model = meta_model_ada)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmeta_train_shallow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-fbed2dbff308>\u001b[0m in \u001b[0;36mmeta_model_pred\u001b[0;34m(models, train_data, test_data, target, y_valid, meta_model)\u001b[0m\n\u001b[1;32m     68\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"old prediction stored: {}, test_meta: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_test_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                     \u001b[0mtemp_test_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "meta_model_temp = MultinomialNB()\n",
    "meta_train_shallow = meta_model_pred(model_set_shallow, test_data = test_features,\n",
    "                              target = train,\n",
    "                              train_data = train_features,\n",
    "                              y_valid = y_fold_renew,\n",
    "                              meta_model = meta_model_ada)\n",
    "meta_train_shallow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 60000)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 100)               800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 606       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 11,513\n",
      "Trainable params: 11,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model = Sequential([Dense(100, input_shape = (7, ), activation='relu'),\n",
    "                      Dense(100, activation='relu'),\n",
    "                    Dense(6, activation='relu'),\n",
    "                      Dense(1, activation='sigmoid')])\n",
    "#nn_model.add(Dense(36, input_shape = (79785, ), activation='relu'))\n",
    "#nn_model.add(Dense(24, activation='relu')\n",
    "#nn_model.add(Dense(6, activation='sigmoid'))\n",
    "nn_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#nn_model.fit(, epochs = 3, batch_size = 32, verbose = 1)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_variable_pickle(y_test_features['toxic'], 'y_test_features_toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set1.append(neigh2)\n",
    "model_set1.append(neigh4)\n",
    "model_set1.append(neigh8)\n",
    "model_set1.append(neigh16)\n",
    "model_set1.append(neigh32)\n",
    "meta_train2 = ready_for_leveltwo(model_set1, train_features, test_features, y_fold_validation, meta_model=gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_valid_y = load_variable_pickle('meta_valid_y.pickle')\n",
    "meta_valid_y.shape, x_train_features.shape\n",
    "y_test_features['toxic'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(train, target, K, random_state ,model):\n",
    "    acc = []\n",
    "    row = train.shape[0]\n",
    "    if row != target.shape[0]:\n",
    "        raise ValueError(\"At least one array required as input\")\n",
    "    num_per_fold = np.int(np.ceil(train.shape[0]/K))\n",
    "    x_train, x_fold, y_train, y_fold1 = train_test_split(train, target, test_size = num_per_fold, random_state = random_state)\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_fold)\n",
    "    acc.append(roc_auc_score(y_fold1, pred))\n",
    "    #print(\"accuracy is {}\".format(accuracy_score(y_fold1, pred)))\n",
    "    i = 1\n",
    "    if train.size != row:\n",
    "        while i < K:\n",
    "            if i != K - 1:\n",
    "                x_fold = train[num_per_fold * i: num_per_fold * (i + 1), :]\n",
    "                y_fold = target[num_per_fold * i: num_per_fold * (i + 1)]\n",
    "                x_train = vstack([train[0: num_per_fold * i, : ], train[num_per_fold * (i + 1): , :]])\n",
    "                y_train = pd.concat([target[0 : num_per_fold * i], target[num_per_fold * (i + 1): ]])\n",
    "                #print(\"x_train: {}, y_train: {}, x_fold: {}, y_fold: {}\".format(x_train.shape, y_train.shape, x_fold.shape, y_fold.shape))\n",
    "            elif i == K-1:\n",
    "                x_fold = train[num_per_fold * i: , :]\n",
    "                y_fold = target[num_per_fold * i: ]\n",
    "                x_train = train[0:num_per_fold * i, :]\n",
    "                y_train = target[0:num_per_fold * i]\n",
    "                \n",
    "            \n",
    "            y_fold1 = pd.concat([y_fold1[:], y_fold[:]])\n",
    "            model.fit(x_train, y_train)\n",
    "            pred1 = model.predict(x_fold)\n",
    "            acc.append(roc_auc_score(y_fold, pred1))\n",
    "            #rint(\"accuracy is {}\".format(accuracy_score(y_fold, pred1)))\n",
    "            pred = np.concatenate((pred, pred1), axis = 0)\n",
    "            i = i + 1\n",
    "    print(\"average roc_auc_score is: {}  for model type: {} \".format(np.mean(acc), type(model)))\n",
    "    return pred# pred_all_testep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_class_cv_mutiple_time(model):\n",
    "    result = np.arange(159571*6).reshape(159571,6)\n",
    "    #all_test_result = np.arange(153164*6).reshape(153164,6)\n",
    "    col = 0\n",
    "    for class_name in class_names:\n",
    "        train_target = train[class_name]\n",
    "        test = test_features\n",
    "        pred1, overall_test_result= cv_split(train = train_features, target = train_target, K = 5, random_state=1023, model=model)\n",
    "        result[:, col] = pred1\n",
    "        all_test_result[:, col] = overall_test_result\n",
    "        #y_fold_result[:, col] = y_fold\n",
    "        col = col + 1\n",
    "        print(\"pred shape: {} and overall_test shape: {} \".format(pred1.shape, all_test_result.shape))\n",
    "    \n",
    "    return result, all_test_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_tune_all_class(model, train, train_t):\n",
    "    score_auc = []\n",
    "    for class_name in class_names:\n",
    "        train_target = train_t[class_name]\n",
    "        cv_score = np.mean(cross_val_score(model, train, train_target, cv=3, scoring='roc_auc'))\n",
    "        scores_auc.append(np.abs(cv_score))\n",
    "        print('auc CV score for class {} is {}'.format(class_name, np.abs(cv_score)))\n",
    "    print('overall CV score for class is {}'.format(np.mean(score_auc)))\n",
    "\n",
    "def param_tune_one_class(model, train, train_target):\n",
    "    cv_score = np.mean(cross_val_score(model, train, train_target, cv=3, scoring='roc_auc'))\n",
    "    print('auc CV score for class is {}'.format(np.abs(cv_score)))\n",
    "    #print('overall CV score for class is {}'.format(np.mean(score_auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "#print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdc_max_depth = [3, 5, 7, 10]\n",
    "#for max_d in gdc_max_depth:\n",
    "gdc = GradientBoostingClassifier(n_estimators=150,# validation_fraction=0.2,\n",
    "     learning_rate = 0.15, max_depth=5, random_state=1023, verbose = True)\n",
    "param_tune_one_class(gdc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc5 = RandomForestClassifier(n_estimators=200, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "param_tune_one_class(rfc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc5 = RandomForestClassifier(n_estimators=200, max_depth = 7, min_samples_leaf= 400, random_state=1023, verbose = True)\n",
    "param_tune_one_class(rfc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_tune = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc', max_depth=12, min_data_in_leaf = 50, num_iterations = 100, \n",
    "                              learning_rate = 0.1\n",
    "                              , device = 'gpu')\n",
    "param_tune_one_class(gbm_tune, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc5 = RandomForestClassifier(n_estimators=300, \n",
    "                              max_depth = 7, random_state=1023, verbose = True)\n",
    "param_tune_one_class(rfc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc5 = RandomForestClassifier(n_estimators= 400,max_depth = 7, random_state=1023, verbose = True)\n",
    "param_tune_one_class(rfc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc5 = ExtraTreesClassifier(n_estimators=200, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc5 = ExtraTreesClassifier(n_estimators=200, min_samples_leaf= 400, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc5 = ExtraTreesClassifier(n_estimators=130, min_samples_leaf= 400, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc5 = ExtraTreesClassifier(n_estimators=400, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc5 = ExtraTreesClassifier(n_estimators=600, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdc = GradientBoostingClassifier(n_estimators=200,# validation_fraction=0.2,\n",
    "     learning_rate = 0.15, max_depth=5, random_state=1023, verbose = True)\n",
    "param_tune_one_class(gdc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdc = GradientBoostingClassifier(n_estimators=200,# validation_fraction=0.2,\n",
    "     learning_rate = 0.15, max_depth=7, random_state=1023, verbose = True)\n",
    "param_tune_one_class(gdc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdc = GradientBoostingClassifier(n_estimators=200,# validation_fraction=0.2,\n",
    "     learning_rate = 0.15, max_depth=10, random_state=1023, verbose = True)\n",
    "param_tune_one_class(gdc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_tune_one_class(nusvc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_auc = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "#classifier = LogisticRegression()\n",
    "#for class_name in class_names:\n",
    "train_target = train['toxic']\n",
    "    #print(train_target.shape)\n",
    "classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    #cv_score = np.mean(cross_val_score(\n",
    "     #   classifier, train_features, train_target, cv=3, scoring='neg_log_loss'))\n",
    "    #scores_auc.append(np.abs(cv_score))\n",
    "    #print('auc CV score for class {} is {}'.format(class_name, np.abs(cv_score)))\n",
    "\n",
    "classifier.fit(train_features, train_target)\n",
    "a = classifier.predict_proba(test_features)\n",
    "print(a.shape)\n",
    "a\n",
    "submission[class_name] = a[:, 1]\n",
    "    #save_varible_pickle(classifier, _logistic, model = True)\n",
    "#print('Total auc CV score is {}'.format(np.mean(scores_auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(train, target, K, random_state ,model):\n",
    "    acc = []\n",
    "    row = train.shape[0]\n",
    "    if row != target.shape[0]:\n",
    "        raise ValueError(\"At least one array required as input\")\n",
    "    num_per_fold = np.int(np.ceil(train.shape[0]/K))\n",
    "    x_train, x_fold, y_train, y_fold1 = train_test_split(train, target, test_size = num_per_fold, random_state = random_state)\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_fold)\n",
    "    acc.append(roc_auc_score(y_fold1, pred))\n",
    "    #print(\"accuracy is {}\".format(accuracy_score(y_fold1, pred)))\n",
    "    i = 1\n",
    "    if train.size != row:\n",
    "        while i < K:\n",
    "            if i != K - 1:\n",
    "                x_fold = train[num_per_fold * i: num_per_fold * (i + 1), :]\n",
    "                y_fold = target[num_per_fold * i: num_per_fold * (i + 1)]\n",
    "                x_train = vstack([train[0: num_per_fold * i, : ], train[num_per_fold * (i + 1): , :]])\n",
    "                y_train = pd.concat([target[0 : num_per_fold * i], target[num_per_fold * (i + 1): ]])\n",
    "                #print(\"x_train: {}, y_train: {}, x_fold: {}, y_fold: {}\".format(x_train.shape, y_train.shape, x_fold.shape, y_fold.shape))\n",
    "            elif i == K-1:\n",
    "                x_fold = train[num_per_fold * i: , :]\n",
    "                y_fold = target[num_per_fold * i: ]\n",
    "                x_train = train[0:num_per_fold * i, :]\n",
    "                y_train = target[0:num_per_fold * i]\n",
    "                \n",
    "            \n",
    "            y_fold1 = pd.concat([y_fold1[:], y_fold[:]])\n",
    "            model.fit(x_train, y_train)\n",
    "            pred1 = model.predict(x_fold)\n",
    "            acc.append(roc_auc_score(y_fold, pred1))\n",
    "            #rint(\"accuracy is {}\".format(accuracy_score(y_fold, pred1)))\n",
    "            pred = np.concatenate((pred, pred1), axis = 0)\n",
    "            i = i + 1\n",
    "    print(\"average roc_auc_score is: {}  for model type: {} \".format(np.mean(acc), type(model)))\n",
    "    return pred# pred_all_testep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
