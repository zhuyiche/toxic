{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/bin/python3'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as K\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import scipy as sp\n",
    "from scipy.sparse import hstack, vstack\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_union\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_variable_pickle(var, name, model = False):\n",
    "    filename = name + '.pickle'\n",
    "    if model:\n",
    "        joblib.dump(var, filename = filename)\n",
    "    else:  \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(var, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_variable_pickle(name, model = False):\n",
    "    filename = name\n",
    "    if model:\n",
    "        return joblib.load(filename = filename)\n",
    "    else:\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_system(os):\n",
    "    if os == 'mac':\n",
    "        train_path = '/Users/yichen/Desktop/toxic/input/train.csv'\n",
    "        test_path = '/Users/yichen/Desktop/toxic/input/test.csv'\n",
    "    elif os == 'linux':\n",
    "        train_path = '/home/yichen/Desktop/toxic/input/train.csv'\n",
    "        test_path = '/home/yichen/Desktop/toxic/input/test.csv'\n",
    "    elif os == 'aws':\n",
    "        train_path = 'train.csv'\n",
    "        test_path = 'test.csv'\n",
    "    \n",
    "    train = pd.read_csv(train_path).fillna(' ')\n",
    "    test = pd.read_csv(test_path).fillna(' ')\n",
    "    return train, test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(true, estimate):\n",
    "    acc = accuracy_score(true, estimate)\n",
    "    logloss = log_loss(true, estimate)\n",
    "    auc = roc_auc_score(true, esimate)\n",
    "    print(\"accuracy score: {}, logloss: {}, auc: {}\".format(acc, logloss, auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153164, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = choose_system('linux')\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = {\n",
    "    \"&lt;3\": \" good \", \":d\": \" good \",\n",
    "    \":dd\": \" good \",\n",
    "    \":p\": \" good \",\n",
    "    \"8)\": \" good \",\n",
    "    \":-)\": \" good \",\n",
    "    \":)\": \" good \",\n",
    "    \";)\": \" good \",\n",
    "    \"(-:\": \" good \",\n",
    "    \"(:\": \" good \",\n",
    "    \"yay!\": \" good \",\n",
    "    \"yay\": \" good \",\n",
    "    \"yaay\": \" good \",\n",
    "    \"yaaay\": \" good \",\n",
    "    \"yaaaay\": \" good \",\n",
    "    \"yaaaaay\": \" good \",\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" bad \",\n",
    "    \":(\": \" bad \",\n",
    "    \":s\": \" bad \",\n",
    "    \":-s\": \" bad \",\n",
    "    \"&lt;3\": \" heart \",\n",
    "    \":d\": \" smile \",\n",
    "    \":p\": \" smile \",\n",
    "    \":dd\": \" smile \",\n",
    "    \"8)\": \" smile \",\n",
    "    \":-)\": \" smile \",\n",
    "    \":)\": \" smile \",\n",
    "    \";)\": \" smile \",\n",
    "    \"(-:\": \" smile \",\n",
    "    \"(:\": \" smile \",\n",
    "    \":/\": \" worry \",\n",
    "    \":&gt;\": \" angry \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" sad \",\n",
    "    \":(\": \" sad \",\n",
    "    \":s\": \" sad \",\n",
    "    \":-s\": \" sad \",\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\",\n",
    "    r\"\\bdon't\\b\": \"do not\",\n",
    "    r\"\\bdoesn't\\b\": \"does not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bcan't\\b\": \"can not\",\n",
    "    r\"\\bcannot\\b\": \"can not\",\n",
    "    r\"\\bi'm\\b\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"r\": \"are\",\n",
    "    \"u\": \"you\",\n",
    "    \"haha\": \"ha\",\n",
    "    \"hahaha\": \"ha\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"cannot\": \"can not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"i'll\" : \"i will\",\n",
    "    \"its\" : \"it is\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"'s\" : \" is\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"weren't\" : \"were not\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [i for i in repl.keys()]\n",
    "\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "ltr = train[\"comment_text\"].tolist()\n",
    "keys = [i for i in repl.keys()]\n",
    "\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "ltr = train[\"comment_text\"].tolist()\n",
    "lte = test[\"comment_text\"].tolist()\n",
    "for i in ltr:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_train_data.append(xx)\n",
    "for i in lte:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_test_data.append(xx)\n",
    "train[\"new_comment_text\"] = new_train_data\n",
    "test[\"new_comment_text\"] = new_test_data\n",
    "\n",
    "trate = train[\"new_comment_text\"].tolist()\n",
    "tete = test[\"new_comment_text\"].tolist()\n",
    "for i, c in enumerate(trate):\n",
    "    trate[i] = re.sub('[^a-zA-Z ?!]+', '', str(trate[i]).lower())\n",
    "for i, c in enumerate(tete):\n",
    "    tete[i] = re.sub('[^a-zA-Z ?!]+', '', tete[i])\n",
    "train[\"comment_text\"] = trate\n",
    "test[\"comment_text\"] = tete\n",
    "del trate, tete\n",
    "train.drop([\"new_comment_text\"], axis=1, inplace=True)\n",
    "test.drop([\"new_comment_text\"], axis=1, inplace=True)\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312735,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "test_features = load_variable_pickle('test_features_save.pickle')\n",
    "train_features = load_variable_pickle('train_features_save.pickle')\n",
    "y_fold_renew = load_variable_pickle('y_fold_valid.pickle')\n",
    "#clf = load_variable_pickle('_logistic_model5.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 60000) (159571, 60000) (159571, 6)\n"
     ]
    }
   ],
   "source": [
    "print(test_features.shape, train_features.shape, y_fold_renew.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "meta_valid_y = load_variable_pickle('meta_valid_y.pickle')\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "nusvc = svm.NuSVC(nu=0.005,random_state = 1023, verbose = True)\n",
    "#rfc= RandomForestClassifier(n_estimators= 50, random_state=11, verbose = True)\n",
    "#submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "MNB = MultinomialNB()\n",
    "gdc = GradientBoostingClassifier(n_estimators=400, \n",
    " learning_rate = 0.1, max_depth=5, random_state=1023, verbose = True)\n",
    "gbm_tune = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc', max_depth=12, min_data_in_leaf = 50, num_iterations = 100, \n",
    "                              learning_rate = 0.1)\n",
    "                              #, device = 'gpu')\n",
    "gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=500)# device = 'gpu')\n",
    "etc = ExtraTreesClassifier(n_estimators=200, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "log_model = LogisticRegression(solver='sag')\n",
    "svc_model = LinearSVC(random_state=1023)\n",
    "\n",
    "\n",
    "model_set1 = []\n",
    "model_set1.append(MNB)\n",
    "model_set1.append(svc_model)\n",
    "model_set1.append(log_model)\n",
    "model_set1.append(etc)\n",
    "#model_set1.append(ada)\n",
    "model_set1.append(gbm_tune)\n",
    "model_set1.append(rfc)\n",
    "\n",
    "#model_set1.append(gdc)\n",
    "model_set1.append(nusvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model_set_shallow = []\n",
    "log_model = LogisticRegression(solver='sag')\n",
    "svc_model = LinearSVC(random_state=1023)\n",
    "gbm_s = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc', max_depth = 3, min_data_in_leaf = 50, num_iterations = 100, \n",
    "                              learning_rate = 0.1)\n",
    "MNB = MultinomialNB()\n",
    "etc_s = ExtraTreesClassifier(n_estimators=100, min_samples_leaf= 100, random_state=1023, verbose = True)\n",
    "rfc_s = RandomForestClassifier(n_estimators = 100, min_samples_leaf= 100, random_state=1023, verbose = True)\n",
    "nusvc_s = svm.NuSVC(nu=0.005,random_state = 1023, verbose = True)\n",
    "#cat_boost = CatBoostClassifier()\n",
    "\n",
    "gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=500)\n",
    "#ada = AdaBoostClassifier(n_estimators= 300)\n",
    "model_set_shallow.append(log_model)\n",
    "model_set_shallow.append(MNB)\n",
    "model_set_shallow.append(svc_model)\n",
    "model_set_shallow.append(etc_s)\n",
    "model_set_shallow.append(rfc_s)\n",
    "model_set_shallow.append(gbm_s)\n",
    "#model_set_shallow.append(nusvc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (79785, 60000), x_test: (79786, 60000), y_train: (79785, 8), y_test: (79786, 8)\n"
     ]
    }
   ],
   "source": [
    "x_train_features, x_test_features, y_train_features, y_test_features = train_test_split(train_features, train,test_size = 0.5,shuffle = False)\n",
    "print(\"x_train: {}, x_test: {}, y_train: {}, y_test: {}\".format(x_train_features.shape, x_test_features.shape, y_train_features.shape, y_test_features.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_K_fold(train, target, K, model):\n",
    "    acc = []\n",
    "    kf = KFold(n_splits=K, random_state=1023)\n",
    "    count = 0\n",
    "    for train_index, test_index in kf.split(train):\n",
    "        X_train, X_test = train[train_index], train[test_index]\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        if count == 0:\n",
    "            pred = model.predict(X_test)\n",
    "            #y_fold_valid = y_test\n",
    "            #acc.append(roc_auc_score(pred, y_test))\n",
    "        else:\n",
    "            pred1 = model.predict(X_test)\n",
    "            pred = np.concatenate((pred, pred1), axis = 0)\n",
    "            #y_fold_valid = np.concatenate((y_fold_valid, y_test))\n",
    "            #acc.append(roc_auc_score(pred1, y_test))\n",
    "        count = count + 1\n",
    "    #print(\"average roc_auc_score for model: {} is: {}\".format(str(type(model)), np.mean(acc)))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79786, 6)\n"
     ]
    }
   ],
   "source": [
    "test_meta_gru= load_variable_pickle('meta_tune_nn_valid/test_meta_gru.pickle')\n",
    "test_meta_lstm = load_variable_pickle('meta_tune_nn_valid/test_meta_lstm.pickle')\n",
    "partB_meta_gru = load_variable_pickle('meta_tune_nn_valid/partB_meta_gru.pickle')\n",
    "partB_meta_lstm = load_variable_pickle('meta_tune_nn_valid/partB_meta_lstm.pickle')\n",
    "gru_y_pred = load_variable_pickle('meta_tune_nn_valid/gru_y_pred.pickle')\n",
    "lstm_y_pred = load_variable_pickle('meta_tune_nn_valid/lstm_y_pred.pickle')\n",
    "print(partB_meta_gru.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model_set_shallow = []\n",
    "log_model = LogisticRegression(solver='sag')\n",
    "svc_model = LinearSVC(random_state=1023)\n",
    "gbm_s = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc', max_depth = 3, min_data_in_leaf = 50, num_iterations = 100, \n",
    "                              learning_rate = 0.1)\n",
    "BNB = BernoulliNB()\n",
    "MNB = MultinomialNB()\n",
    "etc_s = ExtraTreesClassifier(n_estimators=100, min_samples_leaf= 100, random_state=1023, verbose = True)\n",
    "rfc_s = RandomForestClassifier(n_estimators = 100, min_samples_leaf= 100, random_state=1023, verbose = True)\n",
    "nusvc_s = svm.NuSVC(nu=0.005,random_state = 1023, verbose = True)\n",
    "#cat_boost = CatBoostClassifier()\n",
    "gdc = GradientBoostingClassifier(n_estimators=400, \n",
    " learning_rate = 0.1, max_depth=5, random_state=1023, verbose = True)\n",
    "\n",
    "gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        num_leaves=31,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=500)\n",
    "ada = AdaBoostClassifier(n_estimators= 100)\n",
    "#neigh2 = KNeighborsClassifier(n_neighbors=2)\n",
    "\n",
    "#model_set_shallow.append(ada)\n",
    "model_set_shallow.append(log_model)\n",
    "#model_set_shallow.append(BNB)\n",
    "model_set_shallow.append(MNB)\n",
    "model_set_shallow.append(svc_model)\n",
    "model_set_shallow.append(etc_s)\n",
    "model_set_shallow.append(rfc_s)\n",
    "model_set_shallow.append(gbm_s)\n",
    "model_set_shallow.append(nusvc_s)\n",
    "#model_set_shallow.append(neigh2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model_ada = AdaBoostClassifier(n_estimators= 300)\n",
    "meta_model_gbm = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc',\n",
    "                        num_leaves= 128,\n",
    "                        learning_rate=0.1,\n",
    "                        n_estimators=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_model_tune(models, test_data, partA_target, partA, partB, partB_meta_valid ,y_valid, meta_model):\n",
    "    meta_roc_score = []\n",
    "    \n",
    "    \n",
    "    class_counter = 0\n",
    "    #submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "    for class_name in class_names:\n",
    "        os_load_file_path = '/home/yichen/Desktop/toxic/base_model_valid/'\n",
    "        os_load_submission_path = '/home/yichen/Desktop/toxic/submission_valid/'\n",
    "        os_load_submission_path = os_load_file_path + str(class_name) + str(type(meta_model))\n",
    "        os_load_file_path = os_load_file_path + str(class_name) + '/'\n",
    "        print(os_load_file_path)\n",
    "        count = 0\n",
    "        train_target = partA_target[class_name]\n",
    "        for model in models:\n",
    "            name = os_load_file_path +'base_lvl/'+ '_' + class_name + '_' + str(type(model)) + 'base_lvl' + '_' + '.pickle'\n",
    "            if count == 0:\n",
    "                if os.path.exists(name):\n",
    "                    with open(name, 'rb') as f:\n",
    "                        partA_meta = pickle.load(f)\n",
    "                    print(\"old prediction stored: {}, shape: {}\".format(type(model), partA_meta.shape))\n",
    "                else:\n",
    "                    partA_meta = split_K_fold(partA, train_target, 5, model)\n",
    "                    with open(name, 'wb') as f:\n",
    "                        pickle.dump(partA_meta, f, pickle.HIGHEST_PROTOCOL)\n",
    "                count = count + 1\n",
    "            else:\n",
    "                if os.path.exists(name):\n",
    "                    with open(name, 'rb') as f:\n",
    "                        temp = pickle.load(f)\n",
    "                    print(\"old prediction stored: {}, shape: {}\".format(type(model), temp.shape))\n",
    "                else:\n",
    "                    temp = split_K_fold(partA, train_target, 5, model)\n",
    "                    with open(name, 'wb') as f:\n",
    "                        pickle.dump(temp, f, pickle.HIGHEST_PROTOCOL)\n",
    "                partA_meta = np.column_stack((partA_meta, temp))\n",
    "                count = count + 1\n",
    "            print(\"partA.shape: \",partA_meta.shape)\n",
    "        #add nn prediction\n",
    "        \n",
    "        \n",
    "        count = 0                \n",
    "        print(\"cv finished\")\n",
    "        for model in models:\n",
    "            #print(\"count\", count)\n",
    "            partB_meta_name = os_load_file_path + 'partB_meta/' + class_name + '_' 'partB_meta' + '_'+ str(type(model)) + '.pickle'\n",
    "            test_meta_name = os_load_file_path + 'meta_test/' + class_name + '_' + 'test_meta '+ '_' + str(type(model)) + '.pickle'\n",
    "            \n",
    "            if count == 0:\n",
    "                if os.path.exists(partB_meta_name) and os.path.exists(test_meta_name):\n",
    "                    with open(partB_meta_name, 'rb') as f:\n",
    "                        partB_meta = pickle.load(f)\n",
    "                    with open(test_meta_name, 'rb') as f:\n",
    "                        test_meta = pickle.load(f)\n",
    "                        \n",
    "                    print(\"old prediction stored: {}, partB_meta: {}, test_meta: {}\".format(type(model), partB_meta.shape, test_meta.shape))\n",
    "                else:\n",
    "                    model.fit(partA, train_target)\n",
    "                    \n",
    "                    partB_meta = model.predict(partB)\n",
    "                    test_meta = model.predict(test_data)\n",
    "                    \n",
    "                    with open(partB_meta_name, 'wb') as f:\n",
    "                        pickle.dump(partB_meta, f, pickle.HIGHEST_PROTOCOL)\n",
    "                    with open(test_meta_name, 'wb') as f:\n",
    "                        pickle.dump(test_meta, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        \n",
    "                    print(\"model finish predication: {}\".format(str(type(model))))\n",
    "                count = count + 1\n",
    "            else:\n",
    "                if os.path.exists(partB_meta_name) and os.path.exists(test_meta_name):\n",
    "                    with open(partB_meta_name, 'rb') as f:\n",
    "                        temp_partB_meta  = pickle.load(f)\n",
    "                    with open(test_meta_name, 'rb') as f:\n",
    "                        temp_test_meta = pickle.load(f)\n",
    "                        \n",
    "                    print(\"old prediction stored: {}, partB_meta: {}, test_meta: {}\".format(type(model), temp_partB_meta.shape, temp_test_meta.shape))\n",
    "                else:\n",
    "                    model.fit(partA, train_target)\n",
    "                    temp_partB_meta = model.predict(partB)\n",
    "                    temp_test_meta = model.predict(test_data)\n",
    "                    \n",
    "                    with open(partB_meta_name, 'wb') as f:\n",
    "                        pickle.dump(temp_partB_meta, f, pickle.HIGHEST_PROTOCOL)\n",
    "                    with open(test_meta_name, 'wb') as f:\n",
    "                        pickle.dump(temp_test_meta, f, pickle.HIGHEST_PROTOCOL)\n",
    "                        \n",
    "                    print(\"model finish predication: {}\".format(str(type(model))))\n",
    "                    \n",
    "                partB_meta = np.column_stack((partB_meta, temp_partB_meta))\n",
    "                test_meta = np.column_stack((test_meta, temp_test_meta))\n",
    "                #print(\"partB_meta: {}, test_meta: {}\".format(partB_meta.shape, test_meta.shape))\n",
    "                count = count + 1\n",
    "        \n",
    "        #meta_test = np.column_stack((meta_test, gru_meta_test[:, class_counter]))\n",
    "        #meta_test = np.column_stack((meta_test, lstm_meta_test[:, class_counter]))\n",
    "        partA_meta = np.column_stack((partA_meta, gru_y_pred[:, class_counter]))\n",
    "        partA_meta = np.column_stack((partA_meta, lstm_y_pred[:, class_counter]))\n",
    "        partB_meta = np.column_stack((partB_meta, partB_meta_gru[:, class_counter]))\n",
    "        partB_meta = np.column_stack((partB_meta, partB_meta_lstm[:, class_counter]))\n",
    "        #print(\"partA_meta with nn: {} and partB_meta with nn: {}\".format(partA_meta.shape, partB_meta.shape))\n",
    "        \n",
    "        #save for whole nn meta\n",
    "        if class_counter == 0:\n",
    "            partA_meta_allclass = partA_meta\n",
    "            partB_meta_allclass = partB_meta\n",
    "        else:\n",
    "            partA_meta_allclass = np.column_stack((partA_meta_allclass, partA_meta))\n",
    "            partB_meta_allclass = np.column_stack((partB_meta_allclass, partB_meta))\n",
    "        #we needs to take in nn prediction.\n",
    "        #GRU and LSTM for now\n",
    "        \n",
    "        print(\"need this shape: \", partA_meta.shape)\n",
    "        meta_train_valid = y_valid[:, class_counter]\n",
    "        #this is for single class\n",
    "        meta_model_name = '/home/yichen/Desktop/toxic/base_model_valid/' + class_name + '/' + 'meta_model_' + str(type(meta_model))\n",
    "        if type(meta_model) == 'keras.models.Sequential':\n",
    "            print(\"meta_model is nn\")\n",
    "            xt, xte, yt, yte = train_test_split(partA_meta, meta_train_valid, train_size=0.9)\n",
    "            RocAuc = RocAucEvaluation(validation_data=(xte, yte), interval=1)\n",
    "            meta_model.fit(xt, yt, epochs = 2, batch_size = 32, verbose = 1, callbacks=[RocAuc])\n",
    "            partB_meta_pred = meta_model.predict(partB_meta)\n",
    "            print(\"NN print partB_meta_pred should be (, ): \", partB_meta_pred.shape)\n",
    "            ra_score = roc_auc_score(partB_meta_valid[class_name], partB_meta_pred)\n",
    "            print(\"roc_auc_score for class: {} is {}\".format(class_name, ra_score))\n",
    "            meta_roc_score.append(ra_score)\n",
    "        else:\n",
    "            if os.path.exists(meta_model_name):\n",
    "                print(\"meta_model same as last time\")\n",
    "                #meta_gbm = load_variable_pickle('meta_model_<class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>.pickle')\n",
    "            else:\n",
    "                meta_model.fit(partA_meta, meta_train_valid)\n",
    "                partB_meta_pred = meta_model.predict(partB_meta)\n",
    "                #print(\"partB_meta_pred: {} and partB_meta_valid\".format(partB_meta_pred.shape, partB_meta_valid[class_name]))\n",
    "                ra_score = roc_auc_score(partB_meta_valid[class_name], partB_meta_pred)\n",
    "                print(\"roc_auc_score for class: {} is {}\".format(class_name, ra_score))\n",
    "                meta_roc_score.append(ra_score)\n",
    "                with open(meta_model_name, 'wb') as f:\n",
    "                            pickle.dump(partB_meta_pred, f, pickle.HIGHEST_PROTOCOL)\n",
    "                    \n",
    "        #submission[class_name] = meta_y_test_pred\n",
    "        class_counter = class_counter + 1\n",
    "        print(\"round: \")\n",
    "    save_variable_pickle(partA_meta_allclass, 'partA_meta_allclass')\n",
    "    save_variable_pickle(partB_meta_allclass, 'partB_meta_allclass')\n",
    "    print(\"the average roc_auc score is: {}\".format(np.mean(meta_roc_score)))\n",
    "    #submission.to_csv('submission_final.csv', index=False)\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yichen/Desktop/toxic/base_model_valid/toxic/\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (79785,)\n",
      "partA.shape:  (79785,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (79785,)\n",
      "partA.shape:  (79785, 2)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (79785,)\n",
      "partA.shape:  (79785, 3)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 4)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 5)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 6)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, shape: (79785,)\n",
      "partA.shape:  (79785, 7)\n",
      "cv finished\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "need this shape:  (79785, 9)\n",
      "meta_model same as last time\n",
      "round: \n",
      "/home/yichen/Desktop/toxic/base_model_valid/severe_toxic/\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (79785,)\n",
      "partA.shape:  (79785,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (79785,)\n",
      "partA.shape:  (79785, 2)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (79785,)\n",
      "partA.shape:  (79785, 3)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 4)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 5)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 6)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, shape: (79785,)\n",
      "partA.shape:  (79785, 7)\n",
      "cv finished\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "need this shape:  (79785, 9)\n",
      "meta_model same as last time\n",
      "round: \n",
      "/home/yichen/Desktop/toxic/base_model_valid/obscene/\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (79785,)\n",
      "partA.shape:  (79785,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (79785,)\n",
      "partA.shape:  (79785, 2)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (79785,)\n",
      "partA.shape:  (79785, 3)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 4)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 5)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 6)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, shape: (79785,)\n",
      "partA.shape:  (79785, 7)\n",
      "cv finished\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "need this shape:  (79785, 9)\n",
      "meta_model same as last time\n",
      "round: \n",
      "/home/yichen/Desktop/toxic/base_model_valid/threat/\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (79785,)\n",
      "partA.shape:  (79785,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (79785,)\n",
      "partA.shape:  (79785, 2)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (79785,)\n",
      "partA.shape:  (79785, 3)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 4)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 5)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 6)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, shape: (79785,)\n",
      "partA.shape:  (79785, 7)\n",
      "cv finished\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, partB_meta: (79786,), test_meta: (153164,)\n",
      "need this shape:  (79785, 9)\n",
      "meta_model same as last time\n",
      "round: \n",
      "/home/yichen/Desktop/toxic/base_model_valid/insult/\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (79785,)\n",
      "partA.shape:  (79785,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (79785,)\n",
      "partA.shape:  (79785, 2)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (79785,)\n",
      "partA.shape:  (79785, 3)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 4)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partA.shape:  (79785, 6)\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]partA.shape:  (79785, 7)\n",
      "cv finished\n",
      "model finish predication: <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "model finish predication: <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "model finish predication: <class 'sklearn.svm.classes.LinearSVC'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   51.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   15.1s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   25.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model finish predication: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   15.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   26.0s finished\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model finish predication: <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model finish predication: <class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LibSVM]model finish predication: <class 'sklearn.svm.classes.NuSVC'>\n",
      "need this shape:  (79785, 9)\n",
      "Epoch 1/1\n",
      "79785/79785 [==============================] - 5s 61us/step - loss: 0.1027 - acc: 0.9718\n",
      "roc_auc_score for class: insult is 0.8530096525278211\n",
      "round: \n",
      "/home/yichen/Desktop/toxic/base_model_valid/identity_hate/\n",
      "partA.shape:  (79785,)\n",
      "partA.shape:  (79785, 2)\n",
      "partA.shape:  (79785, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   27.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   27.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   26.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   27.3s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   27.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partA.shape:  (79785, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   42.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   43.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   41.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   43.7s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   42.6s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partA.shape:  (79785, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partA.shape:  (79785, 6)\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]partA.shape:  (79785, 7)\n",
      "cv finished\n",
      "model finish predication: <class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "model finish predication: <class 'sklearn.naive_bayes.MultinomialNB'>\n",
      "model finish predication: <class 'sklearn.svm.classes.LinearSVC'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   40.5s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   14.9s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   25.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model finish predication: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   14.9s finished\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   25.4s finished\n",
      "/home/yichen/.local/lib/python3.5/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model finish predication: <class 'sklearn.ensemble.forest.RandomForestClassifier'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model finish predication: <class 'lightgbm.sklearn.LGBMClassifier'>\n",
      "[LibSVM]model finish predication: <class 'sklearn.svm.classes.NuSVC'>\n",
      "need this shape:  (79785, 9)\n",
      "Epoch 1/1\n",
      "79785/79785 [==============================] - 4s 56us/step - loss: 0.0331 - acc: 0.9928\n",
      "roc_auc_score for class: identity_hate is 0.6683320552977111\n",
      "round: \n",
      "the average roc_auc score is: 0.7606708539127661\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a17d778c7ef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                               \u001b[0mpartB_meta_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_valid_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                               meta_model = nn_model)\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmeta_train_shallow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-e49bf5b347fb>\u001b[0m in \u001b[0;36mmeta_model_tune\u001b[0;34m(models, test_data, partA_target, partA, partB, partB_meta_valid, y_valid, meta_model)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;31m#submission.to_csv('submission_final.csv', index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'submission' is not defined"
     ]
    }
   ],
   "source": [
    "meta_train_shallow = meta_model_tune(model_set_shallow, test_data = test_features,\n",
    "                              partA_target = y_train_features, \n",
    "                              partA = x_train_features,\n",
    "                              partB = x_test_features,\n",
    "                              partB_meta_valid = y_test_features,\n",
    "                              y_valid = meta_valid_y, \n",
    "                              meta_model = nn_model)\n",
    "meta_train_shallow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yichen/Desktop/toxic/base_model_valid/toxic/\n",
      "old prediction stored: <class 'sklearn.linear_model.logistic.LogisticRegression'>, shape: (79785,)\n",
      "partA.shape:  (79785,)\n",
      "old prediction stored: <class 'sklearn.naive_bayes.MultinomialNB'>, shape: (79785,)\n",
      "partA.shape:  (79785, 2)\n",
      "old prediction stored: <class 'sklearn.svm.classes.LinearSVC'>, shape: (79785,)\n",
      "partA.shape:  (79785, 3)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 4)\n",
      "old prediction stored: <class 'sklearn.ensemble.forest.RandomForestClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 5)\n",
      "old prediction stored: <class 'lightgbm.sklearn.LGBMClassifier'>, shape: (79785,)\n",
      "partA.shape:  (79785, 6)\n",
      "old prediction stored: <class 'sklearn.svm.classes.NuSVC'>, shape: (79785,)\n",
      "partA.shape:  (79785, 7)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f0341f67b1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                               \u001b[0mpartB_meta_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                               \u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_valid_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                               meta_model = nn_model)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-e49bf5b347fb>\u001b[0m in \u001b[0;36mmeta_model_tune\u001b[0;34m(models, test_data, partA_target, partA, partB, partB_meta_valid, y_valid, meta_model)\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"old prediction stored: {}, shape: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_K_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-e05f55ed7dc2>\u001b[0m in \u001b[0;36msplit_K_fold\u001b[0;34m(train, target, K, model)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \"\"\"\n\u001b[1;32m    472\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_set_shallow.append(ada)\n",
    "meta_model_tune(model_set_shallow, test_data = test_features,\n",
    "                              partA_target = y_train_features, \n",
    "                              partA = x_train_features,\n",
    "                              partB = x_test_features,\n",
    "                              partB_meta_valid = y_test_features,\n",
    "                              y_valid = meta_valid_y, \n",
    "                              meta_model = nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 100)               1000      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 606       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 11,713\n",
      "Trainable params: 11,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model = Sequential([Dense(100, input_shape = (9, ), activation='relu'),\n",
    "                      Dense(100, activation='relu'),\n",
    "                    Dense(6, activation='relu'),\n",
    "                      Dense(1, activation='sigmoid')])\n",
    "#nn_model.add(Dense(36, input_shape = (79785, ), activation='relu'))\n",
    "#nn_model.add(Dense(24, activation='relu')\n",
    "#nn_model.add(Dense(6, activation='sigmoid'))\n",
    "nn_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#nn_model.fit(, epochs = 3, batch_size = 32, verbose = 1)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_variable_pickle(y_test_features['toxic'], 'y_test_features_toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set1.append(neigh2)\n",
    "model_set1.append(neigh4)\n",
    "model_set1.append(neigh8)\n",
    "model_set1.append(neigh16)\n",
    "model_set1.append(neigh32)\n",
    "meta_train2 = ready_for_leveltwo(model_set1, train_features, test_features, y_fold_validation, meta_model=gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_valid_y = load_variable_pickle('meta_valid_y.pickle')\n",
    "meta_valid_y.shape, x_train_features.shape\n",
    "y_test_features['toxic'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(train, target, K, random_state ,model):\n",
    "    acc = []\n",
    "    row = train.shape[0]\n",
    "    if row != target.shape[0]:\n",
    "        raise ValueError(\"At least one array required as input\")\n",
    "    num_per_fold = np.int(np.ceil(train.shape[0]/K))\n",
    "    x_train, x_fold, y_train, y_fold1 = train_test_split(train, target, test_size = num_per_fold, random_state = random_state)\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_fold)\n",
    "    acc.append(roc_auc_score(y_fold1, pred))\n",
    "    #print(\"accuracy is {}\".format(accuracy_score(y_fold1, pred)))\n",
    "    i = 1\n",
    "    if train.size != row:\n",
    "        while i < K:\n",
    "            if i != K - 1:\n",
    "                x_fold = train[num_per_fold * i: num_per_fold * (i + 1), :]\n",
    "                y_fold = target[num_per_fold * i: num_per_fold * (i + 1)]\n",
    "                x_train = vstack([train[0: num_per_fold * i, : ], train[num_per_fold * (i + 1): , :]])\n",
    "                y_train = pd.concat([target[0 : num_per_fold * i], target[num_per_fold * (i + 1): ]])\n",
    "                #print(\"x_train: {}, y_train: {}, x_fold: {}, y_fold: {}\".format(x_train.shape, y_train.shape, x_fold.shape, y_fold.shape))\n",
    "            elif i == K-1:\n",
    "                x_fold = train[num_per_fold * i: , :]\n",
    "                y_fold = target[num_per_fold * i: ]\n",
    "                x_train = train[0:num_per_fold * i, :]\n",
    "                y_train = target[0:num_per_fold * i]\n",
    "                \n",
    "            \n",
    "            y_fold1 = pd.concat([y_fold1[:], y_fold[:]])\n",
    "            model.fit(x_train, y_train)\n",
    "            pred1 = model.predict(x_fold)\n",
    "            acc.append(roc_auc_score(y_fold, pred1))\n",
    "            #rint(\"accuracy is {}\".format(accuracy_score(y_fold, pred1)))\n",
    "            pred = np.concatenate((pred, pred1), axis = 0)\n",
    "            i = i + 1\n",
    "    print(\"average roc_auc_score is: {}  for model type: {} \".format(np.mean(acc), type(model)))\n",
    "    return pred# pred_all_testep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_class_cv_mutiple_time(model):\n",
    "    result = np.arange(159571*6).reshape(159571,6)\n",
    "    #all_test_result = np.arange(153164*6).reshape(153164,6)\n",
    "    col = 0\n",
    "    for class_name in class_names:\n",
    "        train_target = train[class_name]\n",
    "        test = test_features\n",
    "        pred1, overall_test_result= cv_split(train = train_features, target = train_target, K = 5, random_state=1023, model=model)\n",
    "        result[:, col] = pred1\n",
    "        all_test_result[:, col] = overall_test_result\n",
    "        #y_fold_result[:, col] = y_fold\n",
    "        col = col + 1\n",
    "        print(\"pred shape: {} and overall_test shape: {} \".format(pred1.shape, all_test_result.shape))\n",
    "    \n",
    "    return result, all_test_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_tune_all_class(model, train, train_t):\n",
    "    score_auc = []\n",
    "    for class_name in class_names:\n",
    "        train_target = train_t[class_name]\n",
    "        cv_score = np.mean(cross_val_score(model, train, train_target, cv=3, scoring='roc_auc'))\n",
    "        scores_auc.append(np.abs(cv_score))\n",
    "        print('auc CV score for class {} is {}'.format(class_name, np.abs(cv_score)))\n",
    "    print('overall CV score for class is {}'.format(np.mean(score_auc)))\n",
    "\n",
    "def param_tune_one_class(model, train, train_target):\n",
    "    cv_score = np.mean(cross_val_score(model, train, train_target, cv=3, scoring='roc_auc'))\n",
    "    print('auc CV score for class is {}'.format(np.abs(cv_score)))\n",
    "    #print('overall CV score for class is {}'.format(np.mean(score_auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "#print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdc_max_depth = [3, 5, 7, 10]\n",
    "#for max_d in gdc_max_depth:\n",
    "gdc = GradientBoostingClassifier(n_estimators=150,# validation_fraction=0.2,\n",
    "     learning_rate = 0.15, max_depth=5, random_state=1023, verbose = True)\n",
    "param_tune_one_class(gdc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc5 = RandomForestClassifier(n_estimators=200, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "param_tune_one_class(rfc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc5 = RandomForestClassifier(n_estimators=200, max_depth = 7, min_samples_leaf= 400, random_state=1023, verbose = True)\n",
    "param_tune_one_class(rfc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_tune = lgb.LGBMClassifier(objective = 'binary',\n",
    "                        metric = 'auc', max_depth=12, min_data_in_leaf = 50, num_iterations = 100, \n",
    "                              learning_rate = 0.1\n",
    "                              , device = 'gpu')\n",
    "param_tune_one_class(gbm_tune, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc5 = RandomForestClassifier(n_estimators=300, \n",
    "                              max_depth = 7, random_state=1023, verbose = True)\n",
    "param_tune_one_class(rfc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc5 = RandomForestClassifier(n_estimators= 400,max_depth = 7, random_state=1023, verbose = True)\n",
    "param_tune_one_class(rfc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc5 = ExtraTreesClassifier(n_estimators=200, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc5 = ExtraTreesClassifier(n_estimators=200, min_samples_leaf= 400, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc5 = ExtraTreesClassifier(n_estimators=130, min_samples_leaf= 400, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc5 = ExtraTreesClassifier(n_estimators=400, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etc5 = ExtraTreesClassifier(n_estimators=600, min_samples_leaf= 200, random_state=1023, verbose = True)\n",
    "param_tune_one_class(etc5, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdc = GradientBoostingClassifier(n_estimators=200,# validation_fraction=0.2,\n",
    "     learning_rate = 0.15, max_depth=5, random_state=1023, verbose = True)\n",
    "param_tune_one_class(gdc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdc = GradientBoostingClassifier(n_estimators=200,# validation_fraction=0.2,\n",
    "     learning_rate = 0.15, max_depth=7, random_state=1023, verbose = True)\n",
    "param_tune_one_class(gdc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdc = GradientBoostingClassifier(n_estimators=200,# validation_fraction=0.2,\n",
    "     learning_rate = 0.15, max_depth=10, random_state=1023, verbose = True)\n",
    "param_tune_one_class(gdc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_tune_one_class(nusvc, train_features, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_auc = []\n",
    "submission = pd.DataFrame.from_dict({'id': test['id']})\n",
    "#classifier = LogisticRegression()\n",
    "#for class_name in class_names:\n",
    "train_target = train['toxic']\n",
    "    #print(train_target.shape)\n",
    "classifier = LogisticRegression(solver='sag')\n",
    "\n",
    "    #cv_score = np.mean(cross_val_score(\n",
    "     #   classifier, train_features, train_target, cv=3, scoring='neg_log_loss'))\n",
    "    #scores_auc.append(np.abs(cv_score))\n",
    "    #print('auc CV score for class {} is {}'.format(class_name, np.abs(cv_score)))\n",
    "\n",
    "classifier.fit(train_features, train_target)\n",
    "a = classifier.predict_proba(test_features)\n",
    "print(a.shape)\n",
    "a\n",
    "submission[class_name] = a[:, 1]\n",
    "    #save_varible_pickle(classifier, _logistic, model = True)\n",
    "#print('Total auc CV score is {}'.format(np.mean(scores_auc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_split(train, target, K, random_state ,model):\n",
    "    acc = []\n",
    "    row = train.shape[0]\n",
    "    if row != target.shape[0]:\n",
    "        raise ValueError(\"At least one array required as input\")\n",
    "    num_per_fold = np.int(np.ceil(train.shape[0]/K))\n",
    "    x_train, x_fold, y_train, y_fold1 = train_test_split(train, target, test_size = num_per_fold, random_state = random_state)\n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_fold)\n",
    "    acc.append(roc_auc_score(y_fold1, pred))\n",
    "    #print(\"accuracy is {}\".format(accuracy_score(y_fold1, pred)))\n",
    "    i = 1\n",
    "    if train.size != row:\n",
    "        while i < K:\n",
    "            if i != K - 1:\n",
    "                x_fold = train[num_per_fold * i: num_per_fold * (i + 1), :]\n",
    "                y_fold = target[num_per_fold * i: num_per_fold * (i + 1)]\n",
    "                x_train = vstack([train[0: num_per_fold * i, : ], train[num_per_fold * (i + 1): , :]])\n",
    "                y_train = pd.concat([target[0 : num_per_fold * i], target[num_per_fold * (i + 1): ]])\n",
    "                #print(\"x_train: {}, y_train: {}, x_fold: {}, y_fold: {}\".format(x_train.shape, y_train.shape, x_fold.shape, y_fold.shape))\n",
    "            elif i == K-1:\n",
    "                x_fold = train[num_per_fold * i: , :]\n",
    "                y_fold = target[num_per_fold * i: ]\n",
    "                x_train = train[0:num_per_fold * i, :]\n",
    "                y_train = target[0:num_per_fold * i]\n",
    "                \n",
    "            \n",
    "            y_fold1 = pd.concat([y_fold1[:], y_fold[:]])\n",
    "            model.fit(x_train, y_train)\n",
    "            pred1 = model.predict(x_fold)\n",
    "            acc.append(roc_auc_score(y_fold, pred1))\n",
    "            #rint(\"accuracy is {}\".format(accuracy_score(y_fold, pred1)))\n",
    "            pred = np.concatenate((pred, pred1), axis = 0)\n",
    "            i = i + 1\n",
    "    print(\"average roc_auc_score is: {}  for model type: {} \".format(np.mean(acc), type(model)))\n",
    "    return pred# pred_all_testep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
