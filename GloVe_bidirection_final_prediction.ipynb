{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, csv, codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import AveragePooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = {\n",
    "    \"&lt;3\": \" good \", \":d\": \" good \",\n",
    "    \":dd\": \" good \",\n",
    "    \":p\": \" good \",\n",
    "    \"8)\": \" good \",\n",
    "    \":-)\": \" good \",\n",
    "    \":)\": \" good \",\n",
    "    \";)\": \" good \",\n",
    "    \"(-:\": \" good \",\n",
    "    \"(:\": \" good \",\n",
    "    \"yay!\": \" good \",\n",
    "    \"yay\": \" good \",\n",
    "    \"yaay\": \" good \",\n",
    "    \"yaaay\": \" good \",\n",
    "    \"yaaaay\": \" good \",\n",
    "    \"yaaaaay\": \" good \",\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" bad \",\n",
    "    \":(\": \" bad \",\n",
    "    \":s\": \" bad \",\n",
    "    \":-s\": \" bad \",\n",
    "    \"&lt;3\": \" heart \",\n",
    "    \":d\": \" smile \",\n",
    "    \":p\": \" smile \",\n",
    "    \":dd\": \" smile \",\n",
    "    \"8)\": \" smile \",\n",
    "    \":-)\": \" smile \",\n",
    "    \":)\": \" smile \",\n",
    "    \";)\": \" smile \",\n",
    "    \"(-:\": \" smile \",\n",
    "    \"(:\": \" smile \",\n",
    "    \":/\": \" worry \",\n",
    "    \":&gt;\": \" angry \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" sad \",\n",
    "    \":(\": \" sad \",\n",
    "    \":s\": \" sad \",\n",
    "    \":-s\": \" sad \",\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\",\n",
    "    r\"\\bdon't\\b\": \"do not\",\n",
    "    r\"\\bdoesn't\\b\": \"does not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bcan't\\b\": \"can not\",\n",
    "    r\"\\bcannot\\b\": \"can not\",\n",
    "    r\"\\bi'm\\b\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"r\": \"are\",\n",
    "    \"u\": \"you\",\n",
    "    \"haha\": \"ha\",\n",
    "    \"hahaha\": \"ha\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"cannot\": \"can not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"i'll\" : \"i will\",\n",
    "    \"its\" : \"it is\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"'s\" : \" is\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"weren't\" : \"were not\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_variable_pickle(var, name, model = False):\n",
    "    filename = name + '.pickle'\n",
    "    if model:\n",
    "        joblib.dump(var, filename = filename)\n",
    "    else:  \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(var, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_variable_pickle(name, model = False):\n",
    "    filename = name\n",
    "    if model:\n",
    "        return joblib.load(filename = filename)\n",
    "    else:\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_FILE = '/home/yichen/Desktop/toxic/input/train.csv'\n",
    "TEST_DATA_FILE = '/home/yichen/Desktop/toxic/input/test.csv'\n",
    "glove = '/home/yichen/Desktop/DL_pretrain/glove.840B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 30000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_DATA_FILE)\n",
    "test = pd.read_csv(TEST_DATA_FILE)\n",
    "\n",
    "list_sentences_train = train[\"comment_text\"].fillna(\"_na_\").values\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "y = train[list_classes].values\n",
    "list_sentences_test = test[\"comment_text\"].fillna(\"_na_\").values\n",
    "\n",
    "#x_train = train[\"comment_text\"].fillna(\"fillna\").values\n",
    "y_train = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [i for i in repl.keys()]\n",
    "\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "ltr = train[\"comment_text\"].tolist()\n",
    "keys = [i for i in repl.keys()]\n",
    "\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "ltr = train[\"comment_text\"].tolist()\n",
    "lte = test[\"comment_text\"].tolist()\n",
    "for i in ltr:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_train_data.append(xx)\n",
    "for i in lte:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_test_data.append(xx)\n",
    "train[\"new_comment_text\"] = new_train_data\n",
    "test[\"new_comment_text\"] = new_test_data\n",
    "\n",
    "trate = train[\"new_comment_text\"].tolist()\n",
    "tete = test[\"new_comment_text\"].tolist()\n",
    "for i, c in enumerate(trate):\n",
    "    trate[i] = re.sub('[^a-zA-Z ?!]+', '', str(trate[i]).lower())\n",
    "for i, c in enumerate(tete):\n",
    "    tete[i] = re.sub('[^a-zA-Z ?!]+', '', tete[i])\n",
    "train[\"comment_text\"] = trate\n",
    "test[\"comment_text\"] = tete\n",
    "del trate, tete\n",
    "train.drop([\"new_comment_text\"], axis=1, inplace=True)\n",
    "test.drop([\"new_comment_text\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train) + list(list_sentences_test))\n",
    "\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "\n",
    "x_train = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159571, 100), (153164, 100))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_preprocess = load_variable_pickle('glove_preprocessing.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0058391653, 0.48782745)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embs = np.stack(glove_preprocess.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "emb_mean,emb_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: \n",
    "        continue\n",
    "    embedding_vector = glove_preprocess.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159571, 100), (159571, 6))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=1023)\n",
    "county = 0\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    if county == 0:\n",
    "        train_index0 = train_index\n",
    "        test_index0 = test_index\n",
    "    elif county == 1:\n",
    "        train_index1 = train_index\n",
    "        test_index1 = test_index\n",
    "    elif county == 2:\n",
    "        train_index2 = train_index\n",
    "        test_index2 = test_index\n",
    "    elif county == 3:   \n",
    "        train_index3 = train_index\n",
    "        test_index3 = test_index\n",
    "    elif county == 4:\n",
    "        train_index4 = train_index\n",
    "        test_index4 = test_index\n",
    "    county = county + 1\n",
    "#x_train_features, x_test_features, y_train_features, y_test_features\n",
    "x_train0, y_train0, x_test0 = x_train[train_index0], y_train[train_index0], x_train[test_index0]\n",
    "x_train1, y_train1, x_test1 = x_train[train_index1], y_train[train_index1], x_train[test_index1]\n",
    "x_train2, y_train2, x_test2 = x_train[train_index2], y_train[train_index2], x_train[test_index2]\n",
    "x_train3, y_train3, x_test3 = x_train[train_index3], y_train[train_index3], x_train[test_index3]\n",
    "x_train4, y_train4, x_test4 = x_train[train_index4], y_train[train_index4], x_train[test_index4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU_858model():    \n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=True)(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(GRU(80, return_sequences=True))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(6, activation=\"sigmoid\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "gru_model = GRU_858model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train0, y_train0, train_size=0.95,)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121273 samples, validate on 6383 samples\n",
      "Epoch 1/2\n",
      "121273/121273 [==============================] - 440s 4ms/step - loss: 0.0464 - acc: 0.9827 - val_loss: 0.0508 - val_acc: 0.9803\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.988161 \n",
      "\n",
      "Epoch 2/2\n",
      "121273/121273 [==============================] - 428s 4ms/step - loss: 0.0376 - acc: 0.9854 - val_loss: 0.0448 - val_acc: 0.9826\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.988678 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gru_cv0 = gru_model.fit(X_tra, y_tra, batch_size = 32, epochs = 2, validation_data = (X_val, y_val), callbacks=[RocAuc], verbose=1)\n",
    "y_pred0 = gru_model.predict(x_test0, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "gru_model = GRU_858model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train1, y_train1, train_size=0.95,)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121274 samples, validate on 6383 samples\n",
      "Epoch 1/2\n",
      "121274/121274 [==============================] - 430s 4ms/step - loss: 0.0511 - acc: 0.9814 - val_loss: 0.0433 - val_acc: 0.9836\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.985241 \n",
      "\n",
      "Epoch 2/2\n",
      "121274/121274 [==============================] - 558s 5ms/step - loss: 0.0384 - acc: 0.9852 - val_loss: 0.0449 - val_acc: 0.9829\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.985964 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gru_cv1 = gru_model.fit(X_tra, y_tra, batch_size = 32, epochs = 2, validation_data = (X_val, y_val), callbacks=[RocAuc], verbose=1)\n",
    "y_pred1 = gru_model.predict(x_test1, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "gru_model = GRU_858model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train2, y_train2, train_size=0.95,)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121274 samples, validate on 6383 samples\n",
      "Epoch 1/2\n",
      "121274/121274 [==============================] - 578s 5ms/step - loss: 0.0509 - acc: 0.9815 - val_loss: 0.0473 - val_acc: 0.9809\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.987699 \n",
      "\n",
      "Epoch 2/2\n",
      "121274/121274 [==============================] - 424s 4ms/step - loss: 0.0384 - acc: 0.9852 - val_loss: 0.0453 - val_acc: 0.9819\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.987594 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gru_cv2 = gru_model.fit(X_tra, y_tra, batch_size = 32, epochs = 2, validation_data = (X_val, y_val), callbacks=[RocAuc], verbose=1)\n",
    "y_pred2 = gru_model.predict(x_test2, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "gru_model = GRU_858model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train3, y_train3, train_size=0.95,)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121274 samples, validate on 6383 samples\n",
      "Epoch 1/2\n",
      "121274/121274 [==============================] - 428s 4ms/step - loss: 0.0502 - acc: 0.9818 - val_loss: 0.0440 - val_acc: 0.9830\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.985589 \n",
      "\n",
      "Epoch 2/2\n",
      "121274/121274 [==============================] - 427s 4ms/step - loss: 0.0384 - acc: 0.9849 - val_loss: 0.0440 - val_acc: 0.9829\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.986629 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gru_cv3 = gru_model.fit(X_tra, y_tra, batch_size = 32, epochs = 2, validation_data = (X_val, y_val), callbacks=[RocAuc], verbose=1)\n",
    "y_pred3 = gru_model.predict(x_test3, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "gru_model = GRU_858model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train4, y_train4, train_size=0.95,)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121274 samples, validate on 6383 samples\n",
      "Epoch 1/2\n",
      "121274/121274 [==============================] - 419s 3ms/step - loss: 0.0508 - acc: 0.9814 - val_loss: 0.0429 - val_acc: 0.9835\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.983100 \n",
      "\n",
      "Epoch 2/2\n",
      "121274/121274 [==============================] - 411s 3ms/step - loss: 0.0383 - acc: 0.9850 - val_loss: 0.0422 - val_acc: 0.9833\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.982665 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gru_cv4 = gru_model.fit(X_tra, y_tra, batch_size = 32, epochs = 2, validation_data = (X_val, y_val), callbacks=[RocAuc], verbose=1)\n",
    "y_pred4 = gru_model.predict(x_test4, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "gru_model = GRU_858model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95,)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151592 samples, validate on 7979 samples\n",
      "Epoch 1/2\n",
      "151592/151592 [==============================] - 567s 4ms/step - loss: 0.0498 - acc: 0.9817 - val_loss: 0.0402 - val_acc: 0.9842\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.989278 \n",
      "\n",
      "Epoch 2/2\n",
      "151592/151592 [==============================] - 552s 4ms/step - loss: 0.0383 - acc: 0.9851 - val_loss: 0.0403 - val_acc: 0.9840\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.989321 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gru_metab = gru_model.fit(X_tra, y_tra, batch_size = 32, epochs = 2, validation_data = (X_val, y_val), callbacks=[RocAuc], verbose=1)\n",
    "test_meta_gru = gru_model.predict(x_test, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_70model():    \n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=True)(inp)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Bidirectional(LSTM(200, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    x = concatenate([avg_pool, max_pool])\n",
    "    \n",
    "    x = Dense(100, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs = inp, outputs = x)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam',  metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lstm_model = lstm_70model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train0, y_train0, train_size=0.95, random_state=1023)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121273 samples, validate on 6383 samples\n",
      "Epoch 1/2\n",
      "121273/121273 [==============================] - 605s 5ms/step - loss: 0.0520 - acc: 0.9812 - val_loss: 0.0426 - val_acc: 0.9842\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.984570 \n",
      "\n",
      "Epoch 2/2\n",
      "121273/121273 [==============================] - 642s 5ms/step - loss: 0.0392 - acc: 0.9847 - val_loss: 0.0437 - val_acc: 0.9840\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.984872 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_cv0 = lstm_model.fit(X_tra, y_tra, batch_size = 32, epochs = 2, validation_data = (X_val, y_val), callbacks=[RocAuc], verbose=1)\n",
    "lstm_y_pred0 = lstm_model.predict(x_test0, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lstm_model = lstm_70model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train1, y_train1, train_size=0.95, random_state=1023)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121274 samples, validate on 6383 samples\n",
      "Epoch 1/2\n",
      "121274/121274 [==============================] - 708s 6ms/step - loss: 0.0514 - acc: 0.9813 - val_loss: 0.0456 - val_acc: 0.9820\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.988200 \n",
      "\n",
      "Epoch 2/2\n",
      "121274/121274 [==============================] - 620s 5ms/step - loss: 0.0394 - acc: 0.9847 - val_loss: 0.0437 - val_acc: 0.9833\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.986701 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_cv1 = lstm_model.fit(X_tra, y_tra, batch_size = 32, epochs = 2, validation_data = (X_val, y_val), callbacks=[RocAuc], verbose=1)\n",
    "lstm_y_pred1 = lstm_model.predict(x_test1, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lstm_model = lstm_70model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train2, y_train2, train_size=0.95, random_state=1023)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121274 samples, validate on 6383 samples\n",
      "Epoch 1/2\n",
      "121274/121274 [==============================] - 696s 6ms/step - loss: 0.0517 - acc: 0.9813 - val_loss: 0.0449 - val_acc: 0.9820\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.985824 \n",
      "\n",
      "Epoch 2/2\n",
      "121274/121274 [==============================] - 633s 5ms/step - loss: 0.0396 - acc: 0.9845 - val_loss: 0.0451 - val_acc: 0.9825\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.986196 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_cv2 = lstm_model.fit(X_tra, y_tra, batch_size = 32, epochs = 2, validation_data = (X_val, y_val), callbacks=[RocAuc], verbose=1)\n",
    "lstm_y_pred2 = lstm_model.predict(x_test2, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lstm_model = lstm_70model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train3, y_train3, train_size=0.95, random_state=1023)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121274 samples, validate on 6383 samples\n",
      "Epoch 1/2\n",
      "121274/121274 [==============================] - 734s 6ms/step - loss: 0.0515 - acc: 0.9813 - val_loss: 0.0409 - val_acc: 0.9840\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.986770 \n",
      "\n",
      "Epoch 2/2\n",
      "121274/121274 [==============================] - 870s 7ms/step - loss: 0.0393 - acc: 0.9845 - val_loss: 0.0411 - val_acc: 0.9841\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.989230 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_cv3 = lstm_model.fit(X_tra, y_tra, batch_size = 32, epochs = 2, validation_data = (X_val, y_val), callbacks=[RocAuc], verbose=1)\n",
    "lstm_y_pred3 = lstm_model.predict(x_test3, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lstm_model = lstm_70model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train4, y_train4, train_size=0.95, random_state=1023)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121274 samples, validate on 6383 samples\n",
      "Epoch 1/2\n",
      "121274/121274 [==============================] - 638s 5ms/step - loss: 0.0513 - acc: 0.9814 - val_loss: 0.0415 - val_acc: 0.9843\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.985604 \n",
      "\n",
      "Epoch 2/2\n",
      "121274/121274 [==============================] - 634s 5ms/step - loss: 0.0391 - acc: 0.9846 - val_loss: 0.0410 - val_acc: 0.9848\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.985085 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_cv4 = lstm_model.fit(X_tra, y_tra, batch_size = 32, epochs = 2, validation_data = (X_val, y_val), callbacks=[RocAuc], verbose=1)\n",
    "lstm_y_pred4 = lstm_model.predict(x_test4, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159571, 6), (159571, 6))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_y_pred = lstm_y_pred0\n",
    "lstm_y_pred = np.concatenate((lstm_y_pred, lstm_y_pred1), axis = 0)\n",
    "lstm_y_pred = np.concatenate((lstm_y_pred, lstm_y_pred2), axis = 0)\n",
    "lstm_y_pred = np.concatenate((lstm_y_pred, lstm_y_pred3), axis = 0)\n",
    "lstm_y_pred = np.concatenate((lstm_y_pred, lstm_y_pred4), axis = 0)\n",
    "gru_y_pred = y_pred0\n",
    "gru_y_pred = np.concatenate((gru_y_pred, y_pred1), axis = 0)\n",
    "gru_y_pred = np.concatenate((gru_y_pred, y_pred2), axis = 0)\n",
    "gru_y_pred = np.concatenate((gru_y_pred, y_pred3), axis = 0)\n",
    "gru_y_pred = np.concatenate((gru_y_pred, y_pred4), axis = 0)\n",
    "gru_y_pred.shape, lstm_y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yichen/.local/lib/python3.5/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lstm_model = lstm_70model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95,)\n",
    "RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 151592 samples, validate on 7979 samples\n",
      "Epoch 1/2\n",
      "151592/151592 [==============================] - 881s 6ms/step - loss: 0.0505 - acc: 0.9815 - val_loss: 0.0414 - val_acc: 0.9845\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.989182 \n",
      "\n",
      "Epoch 2/2\n",
      "151592/151592 [==============================] - 799s 5ms/step - loss: 0.0393 - acc: 0.9846 - val_loss: 0.0397 - val_acc: 0.9850\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.989577 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "lstm_metab = lstm_model.fit(X_tra, y_tra, batch_size = 32, epochs = 2, validation_data = (X_val, y_val), callbacks=[RocAuc], verbose=1)\n",
    "test_meta_lstm = lstm_model.predict(x_test, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Conv2D, Flatten, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_variable_pickle(test_meta_gru, 'test_meta_gru')\n",
    "save_variable_pickle(test_meta_lstm, 'test_meta_lstm')\n",
    "#save_variable_pickle(partB_meta_gru, 'partB_meta_gru')\n",
    "#save_variable_pickle(partB_meta_lstm, 'partB_meta_lstm')\n",
    "save_variable_pickle(gru_y_pred, 'gru_y_pred')\n",
    "save_variable_pickle(lstm_y_pred, 'lstm_y_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():    \n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x = Conv1D(128, 5, activation = 'relu')\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Conv1D(128, 5, activation = 'relu')\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Conv1D(128, 5, activation = 'relu')\n",
    "    x = MaxPooling1D(35)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs = inp, outputs = x)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam',  metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = cnn_model()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
